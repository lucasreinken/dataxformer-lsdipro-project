{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ac563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 1000\n",
    "with open(\"../data/tables.json\", \"r\") as infile, open(f\"../data/tables_{l}.json\", \"w\") as outfile:\n",
    "    for i, line in enumerate(infile):\n",
    "        if i >= l:\n",
    "            break\n",
    "        outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bda59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch \n",
    "import matplotlib.pyplot as plt \n",
    "import collections\n",
    "import nltk \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk import ngrams\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from functools import cache\n",
    "import cProfile\n",
    "import pstats\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599db92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def get_clock_time_in_milli_sec():\n",
    "    return int(time.time() * 1000)\n",
    "\n",
    "def print_time(milli_sec):\n",
    "    hours, remainder = divmod(milli_sec, 1000 * 60 * 60)\n",
    "    minutes, remainder = divmod(remainder, 1000 * 60)\n",
    "    seconds, milli_seconds = divmod(remainder, 1000)\n",
    "    components = []\n",
    "    if hours:\n",
    "        components.append(f\"{hours}h\")\n",
    "    if minutes:\n",
    "        components.append(f\"{minutes}m\")\n",
    "    if seconds:\n",
    "        components.append(f\"{seconds}s\")\n",
    "    if milli_seconds:\n",
    "        components.append(f\"{milli_seconds}ms\")\n",
    "    print(f\"{milli_sec}[{':'.join(components)}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af43508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_list(dfs):\n",
    "    return [[[cell.get('text', '') for cell in row] for row in table_data] for table_data in dfs['tableData']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563bef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def process_words(text:str)->list: \n",
    "    sentence = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    words = word_tokenize(sentence)\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccfeb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46752eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def stem_cached(word):\n",
    "    return ps.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9880016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_projections(table_list,\n",
    "                       start_table_index,\n",
    "                       projections,\n",
    "                       stemmer, \n",
    "                       stop_words: list = None, \n",
    "                       min_word_len = 0, \n",
    "                       create_ngrams:bool = False, \n",
    "                       ngrams_size:int = 2\n",
    "                       ) -> dict: \n",
    "\n",
    "    ps = stemmer\n",
    "    \n",
    "    if stop_words: \n",
    "        stemmed_stopwords = {ps.stem_cached(w) for w in stop_words}\n",
    "    else:\n",
    "        stemmed_stopwords = set()\n",
    "\n",
    "    for table_index, table in enumerate(table_list): \n",
    "        for row_index, row in enumerate(table): \n",
    "            for column_index, cell in enumerate(row): \n",
    "\n",
    "                words = process_words(cell)\n",
    "\n",
    "                if create_ngrams: \n",
    "                    ngram_stem_set = set()\n",
    "\n",
    "                for word in words: \n",
    "                    stemmed_word = stem_cached(word)\n",
    "                        \n",
    "                    if stemmed_word not in stemmed_stopwords and len(stemmed_word) >= min_word_len: \n",
    "\n",
    "                        projections.setdefault(stemmed_word, set()).add((table_index, row_index, column_index))\n",
    "\n",
    "                        if create_ngrams: \n",
    "                            ngram_stem_set.update(stemmed_word)\n",
    "                \n",
    "                if create_ngrams: \n",
    "                    created_ngrams = ngrams(ngram_stem_set, ngrams_size)\n",
    "                    for created_ngram in created_ngrams: \n",
    "                        projections.setdefault(created_ngram, set()).add((table_index, row_index, column_index))\n",
    "    \n",
    "    return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed0f826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables_df(table_chunk, start_table_index, tables_df): \n",
    "\n",
    "    new_tables_df = pd.DataFrame({\n",
    "        \"id\": range(start_table_index, start_table_index + len(table_chunk)),\n",
    "        \"pgTitle\": table_chunk.get('pgTitle', ''),\n",
    "        \"sectionTitle\": table_chunk.get('sectionTitle', ''),\n",
    "        \"tableCaption\": table_chunk.get('tableCaption', ''),\n",
    "        \"prior\": [0.5] * len(table_chunk),\n",
    "        \"score\": [None] * len(table_chunk)\n",
    "    })\n",
    "\n",
    "    if not tables_df.empty:\n",
    "        tables_df = pd.concat([tables_df, new_tables_df], ignore_index=True)\n",
    "    else:\n",
    "        tables_df = new_tables_df\n",
    "\n",
    "    return tables_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdffcbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(value, create_ngrams:bool = False, ngram_size:int = 2) -> list: ####Umbenennen \n",
    "    \"\"\"\n",
    "    Returns the tokenized and stemed version of a Value\n",
    "    \"\"\"\n",
    "    words = process_words(value)\n",
    "\n",
    "    stemmed_words = [stem_cached(word) for word in words]\n",
    "\n",
    "    if create_ngrams: \n",
    "        created_ngrams = ngrams(stemmed_words, ngram_size)\n",
    "        stemmed_words.extend(list(created_ngrams))\n",
    "        \n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca8a4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing(cleaned_values:list, projections:dict)->dict: \n",
    "    \"\"\"\n",
    "    Return a dict of all the Examples found in the projections\n",
    "    In: \n",
    "        Cleaned_Values: A List of all the Stemped Versions of one Example given\n",
    "        Projections: A Dict of Projections of all given Tables\n",
    "    Out: \n",
    "        Index_Dict: A dict of all the positions where the Example was found\n",
    "                    Form: Key: (Table_ID, Row_ID) -> Value: (Col_ID)\n",
    "    \"\"\"\n",
    "    index_dict = dict() \n",
    "    \n",
    "    for value in cleaned_values: \n",
    "        value_index = projections.get(value, None)\n",
    "\n",
    "        if value_index: \n",
    "            for index_pair in value_index: \n",
    "                table_id, row_id, col_id = index_pair \n",
    "                index_dict.setdefault((table_id, row_id), set()).add((col_id))\n",
    "    \n",
    "    return index_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81765323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareit(dictx:dict, dicty:dict, sub_key_mode:bool = False)-> list: \n",
    "    \"\"\"\n",
    "    Compairs two Dicts with eachother and return a Dict of Intersections between Dicts \n",
    "    In: \n",
    "        Dictx: Dict of the Form Key: (Table_ID, Row_ID) -> Value: (Row_ID(s))\n",
    "        Dicty: Dict of the Form Key: (Table_ID, Row_ID) -> Value: (Row_ID(s))\n",
    "        Sub_Key_Mode: Bool that assures that the output dict is in a Form that another instance of \n",
    "                      Compareit could use it\n",
    "    Out: \n",
    "        Possible_Tables_Dict/ Subkey_Dict: A Dict of all Intersections between Dictx and Dicty\n",
    "                                           In the Form of Dictx/ Dicty if Sub_Key_Mode == True \n",
    "    \"\"\"\n",
    "\n",
    "    if not sub_key_mode: \n",
    "        possible_tables_dict = dict()\n",
    "    else: \n",
    "        subkey_dict = dict()\n",
    "    intersecting_keys = set(dictx) & set(dicty)\n",
    "    for key in intersecting_keys: \n",
    "        table_id, row_id = key\n",
    "        for x_col_id in dictx[key]: \n",
    "            for y_col_id in dicty[key]: \n",
    "                if not sub_key_mode: \n",
    "                    possible_tables_dict.setdefault(table_id, set()).add((row_id, (x_col_id, y_col_id)))\n",
    "                    \n",
    "                else: \n",
    "                    subkey_dict.setdefault(key, set()).add((x_col_id, y_col_id))\n",
    "    if not sub_key_mode: \n",
    "        return possible_tables_dict\n",
    "    else: \n",
    "        return subkey_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "494edfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def querry_thunel(example_pairs:list, projections:dict, tau:int=1):\n",
    "    \"\"\"\n",
    "    Perfoms the complete Querrying Web Tables Operation. \n",
    "    In: \n",
    "        Example_Pairs: A List of the Semmantic Mapping \n",
    "        Projections: A Dict of Projections of all given Tables\n",
    "        Tau: An Int which indicates how many Example_pairs must be in a Table to count as relevant\n",
    "    Out: \n",
    "        Tables: A Dict of all relevant Tables \n",
    "                Form: Key: Table_ID -> Value: (Row_ID, (XColumn_ID, YColumn_ID))\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(example_pairs) < tau: \n",
    "        raise ValueError(f\"The Cardinality of given Example_Pairs {len(example_pairs)} must be greater or qual then Tau: {tau}!\")\n",
    "    \n",
    "\n",
    "    possible_tables = dict()\n",
    "\n",
    "    for tup in example_pairs: \n",
    "        list_of_keys = list()\n",
    "        for val in tup: \n",
    "            \n",
    "            if isinstance(val, tuple): \n",
    "                list_of_subkeys = list()\n",
    "                for sub_key in val: \n",
    "                    cleaned_sub_key = cleaner(sub_key)\n",
    "                    index_of_sub_key = indexing(cleaned_sub_key, projections)\n",
    "                    list_of_subkeys.append(index_of_sub_key)\n",
    "                key_val = compareit(*list_of_subkeys, sub_key_mode=True)\n",
    "                \n",
    "            \n",
    "            else: \n",
    "                cleaned_key = cleaner(val)\n",
    "                index_of_key = indexing(cleaned_key, projections)\n",
    "                key_val = index_of_key\n",
    "            \n",
    "            list_of_keys.append(key_val)\n",
    "        \n",
    "        \n",
    "\n",
    "        compared_things = compareit(*list_of_keys)\n",
    "        possible_tables.update(compared_things)\n",
    "\n",
    "    tables = dict()\n",
    "    for key in possible_tables: \n",
    "        if len(possible_tables[key]) >= tau: \n",
    "            tables[key] = possible_tables[key]\n",
    "\n",
    "    return tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cdb46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_json(path, csize):\n",
    "    iter_chunk = pd.read_json(path, lines=True, chunksize=csize)\n",
    "    for chunk in iter_chunk:\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16614751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with getter and setter and global / environment variables\n",
    "\n",
    "def update_table_scores(query_answers, query_tables_ids, tables_df, answer_scores, table_scores):\n",
    "    alpha = 0.99\n",
    "    \n",
    "    for query_table_id in query_tables_ids:\n",
    "        good = 0\n",
    "        bad = 0\n",
    "        covered_query_answers_x = set()\n",
    "\n",
    "        table_answers = set(zip(\n",
    "                query_answers.loc[query_answers['table_id'] == query_table_id, 'answer_x'],\n",
    "                query_answers.loc[query_answers['table_id'] == query_table_id, 'answer_y']\n",
    "                ))\n",
    "\n",
    "        for table_answer in table_answers:\n",
    "            covered_query_answers_x.add(table_answer[0])\n",
    "            table_answer_score = answer_scores[table_answer]\n",
    "            if (table_answer_score == max([score for (x, _), score in answer_scores.items() if x == table_answer[0]])):\n",
    "                good += table_answer_score\n",
    "            else:\n",
    "                bad += 1\n",
    "\n",
    "        unseen_x = 0\n",
    "        for query_answer in zip(query_answers['answer_x'], query_answers['answer_y']):\n",
    "            if not query_answer[0] in covered_query_answers_x:\n",
    "                unseen_x += max([score for answer, score in answer_scores.items() if answer == query_answer])\n",
    "\n",
    "        table_prior = tables_df.loc[tables_df['id'] == query_table_id, 'prior'].iloc[0]\n",
    "\n",
    "        table_score = alpha * ((table_prior * good) / (table_prior * good + (1-table_prior) * (bad + unseen_x)))\n",
    "        table_scores[query_table_id] = table_score\n",
    "\n",
    "    return table_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27bc9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_answer_scores(query_answers, query_answers_set, answer_scores, table_scores):\n",
    "\n",
    "    query_answer_xs = {x for x, _ in query_answers_set}\n",
    "    \n",
    "    for query_answers_x in query_answer_xs:\n",
    "        \n",
    "        x_answers = {answer for answer in query_answers_set if answer[0] == query_answers_x}\n",
    "\n",
    "        score_of_none = 1\n",
    "        \n",
    "        for table_id in query_answers.loc[query_answers['answer_x'] == query_answers_x, 'table_id']:\n",
    "            score_of_none *= (1-table_scores[table_id])\n",
    "            for x_answer in x_answers:\n",
    "                answer_score = 1\n",
    "\n",
    "                if x_answer in set(zip(\n",
    "                    query_answers.loc[query_answers['table_id'] == table_id, 'answer_x'],\n",
    "                    query_answers.loc[query_answers['table_id'] == table_id, 'answer_y']\n",
    "                )):\n",
    "                    answer_score *= table_scores[table_id]\n",
    "                else:\n",
    "                    answer_score *= (1-table_scores[table_id])\n",
    "\n",
    "        for x_answer in x_answers:\n",
    "            answer_scores[x_answer] = answer_scores[x_answer] / (score_of_none + np.sum(np.array([score for answer, score in answer_scores if answer in x_answers])))\n",
    "\n",
    "    return answer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4478047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_answers format: dataframe(answer_x, answer_y, table_id)\n",
    "\n",
    "def expectation_maximization(query_answers, epsilon, tables_df):\n",
    "    query_tables_ids = set(query_answers['table_id'])\n",
    "    query_answers_set = set(zip(query_answers['answer_x'], query_answers['answer_y']))\n",
    "\n",
    "    # which values for initilization?\n",
    "    answer_scores = {answer: 1.0 for answer in query_answers_set}\n",
    "    table_scores = {table_id: 1.0 for table_id in query_tables_ids}\n",
    "\n",
    "    delta_score = np.inf\n",
    "\n",
    "    old_answer_scores = dict()\n",
    "\n",
    "    while delta_score > epsilon:\n",
    "\n",
    "        # add line 6-15?\n",
    "\n",
    "        old_answer_scores = deepcopy(answer_scores)\n",
    "\n",
    "        table_scores = update_table_scores(query_answers, query_tables_ids, tables_df, answer_scores, table_scores)\n",
    "        answer_scores = update_answer_scores(query_answers, query_answers_set, answer_scores, table_scores)\n",
    "\n",
    "        delta_score = np.sum(np.abs(\n",
    "                np.array([answer_scores[answer] for answer in query_answers_set]) -\n",
    "                np.array([old_answer_scores[answer] for answer in query_answers_set])\n",
    "            ))\n",
    "\n",
    "    print(table_scores)\n",
    "\n",
    "    return answer_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc02abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    ('FCB', 'FC Barcelona'),\n",
    "    ('FCB', 'FC Bayern München'),\n",
    "    ('FCB', 'Football Club Barcelona'),\n",
    "    ('NYC', 'New York City'),\n",
    "    ('NYC', 'NY City'),\n",
    "    ('USA', 'United States'),\n",
    "    ('USA', 'U.S.A.'),\n",
    "    ('USA', 'United States of America'),\n",
    "    ('IBM', 'International Business Machines'),\n",
    "    ('IBM', 'IBM Corp.'),\n",
    "    ('MIT', 'Massachusetts Institute of Technology'),\n",
    "    ('MIT', 'M.I.T.'),\n",
    "    ('NVIDIA', 'Nvidia Corporation'),\n",
    "    ('NVIDIA', 'NVIDIA Inc.'),\n",
    "    ('UCLA', 'University of California, Los Angeles'),\n",
    "    ('UCLA', 'U.C.L.A.'),\n",
    "    ('Dept.', 'Department'),\n",
    "    ('Dept.', 'Dept'),\n",
    "    ('Google', 'Google LLC'),\n",
    "    ('Google', 'Google Inc.'),\n",
    "]\n",
    "\n",
    "query_answers = pd.DataFrame(rows, columns=['answer_x', 'answer_y'])\n",
    "query_answers['table_id'] = list(range(10)) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5240b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_table_index = 0\n",
    "\n",
    "csize = 10\n",
    "path = \"../data/tables_10.json\"\n",
    "\n",
    "tables_df = pd.DataFrame()\n",
    "\n",
    "for table_chunk in iter_json(path, csize):\n",
    "    tables_df = create_tables_df(table_chunk, start_table_index, tables_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3721255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------------------------------------------------------+---------------------------+---------------------------+---------+---------+\n",
      "|    |   id | pgTitle                                               | sectionTitle              | tableCaption              |   prior | score   |\n",
      "|----+------+-------------------------------------------------------+---------------------------+---------------------------+---------+---------|\n",
      "|  0 |    0 | Mid Antrim (Northern Ireland Parliament constituency) | Members of Parliament     | Members of Parliament     |     0.5 |         |\n",
      "|  1 |    1 | Römer (crater)                                        | Satellite craters         | Satellite craters         |     0.5 |         |\n",
      "|  2 |    2 | Whispermoon                                           |                           | Track listing             |     0.5 |         |\n",
      "|  3 |    3 | Khalsa Diwan Society Vancouver                        | First executive committee | First executive committee |     0.5 |         |\n",
      "|  4 |    4 | Julien Leparoux                                       | Year-end charts           | Year-end charts           |     0.5 |         |\n",
      "|  5 |    5 | Barton Academy (Vermont)                              | Principals                | Principals                |     0.5 |         |\n",
      "|  6 |    6 | Real Voice                                            | Charts                    | Charts                    |     0.5 |         |\n",
      "|  7 |    7 | Acrimony                                              | Albums                    | Albums                    |     0.5 |         |\n",
      "|  8 |    8 | Acrimony                                              | EPs and Singles           | EPs and Singles           |     0.5 |         |\n",
      "|  9 |    9 | James Fiennes, 1st Baron Saye and Sele                | Ancestry                  | Ancestry                  |     0.5 |         |\n",
      "+----+------+-------------------------------------------------------+---------------------------+---------------------------+---------+---------+\n",
      "+----+------------+---------------------------------------+------------+\n",
      "|    | answer_x   | answer_y                              |   table_id |\n",
      "|----+------------+---------------------------------------+------------|\n",
      "|  0 | FCB        | FC Barcelona                          |          0 |\n",
      "|  1 | FCB        | FC Bayern München                     |          1 |\n",
      "|  2 | FCB        | Football Club Barcelona               |          2 |\n",
      "|  3 | NYC        | New York City                         |          3 |\n",
      "|  4 | NYC        | NY City                               |          4 |\n",
      "|  5 | USA        | United States                         |          5 |\n",
      "|  6 | USA        | U.S.A.                                |          6 |\n",
      "|  7 | USA        | United States of America              |          7 |\n",
      "|  8 | IBM        | International Business Machines       |          8 |\n",
      "|  9 | IBM        | IBM Corp.                             |          9 |\n",
      "| 10 | MIT        | Massachusetts Institute of Technology |          0 |\n",
      "| 11 | MIT        | M.I.T.                                |          1 |\n",
      "| 12 | NVIDIA     | Nvidia Corporation                    |          2 |\n",
      "| 13 | NVIDIA     | NVIDIA Inc.                           |          3 |\n",
      "| 14 | UCLA       | University of California, Los Angeles |          4 |\n",
      "| 15 | UCLA       | U.C.L.A.                              |          5 |\n",
      "| 16 | Dept.      | Department                            |          6 |\n",
      "| 17 | Dept.      | Dept                                  |          7 |\n",
      "| 18 | Google     | Google LLC                            |          8 |\n",
      "| 19 | Google     | Google Inc.                           |          9 |\n",
      "+----+------------+---------------------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(tables_df, headers='keys', tablefmt='psql'))\n",
    "print(tabulate(query_answers, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "972175f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: nan, 1: nan, 2: nan, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8212\\3407514113.py:25: RuntimeWarning: overflow encountered in scalar divide\n",
      "  answer_scores[x_answer] = answer_scores[x_answer] / (score_of_none + np.sum(np.array([score for answer, score in answer_scores if answer in x_answers])))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_8212\\823063290.py:31: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  table_score = alpha * ((table_prior * good) / (table_prior * good + (1-table_prior) * (bad + unseen_x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{('IBM', 'International Business Machines'): 3.9144124360393073,\n",
       " ('FCB', 'FC Bayern München'): nan,\n",
       " ('MIT', 'M.I.T.'): nan,\n",
       " ('Dept.', 'Dept'): 19715424296.18966,\n",
       " ('Google', 'Google LLC'): 3.9144124360393073,\n",
       " ('USA', 'U.S.A.'): 1816626212302610.5,\n",
       " ('USA', 'United States'): 1816626212302610.5,\n",
       " ('Dept.', 'Department'): 19715424296.18966,\n",
       " ('UCLA', 'University of California, Los Angeles'): 196177.20327473822,\n",
       " ('USA', 'United States of America'): 1816626212302610.5,\n",
       " ('FCB', 'FC Barcelona'): nan,\n",
       " ('NYC', 'New York City'): 4.532921321014106,\n",
       " ('MIT', 'Massachusetts Institute of Technology'): nan,\n",
       " ('NVIDIA', 'Nvidia Corporation'): nan,\n",
       " ('UCLA', 'U.C.L.A.'): 196177.20327473822,\n",
       " ('NVIDIA', 'NVIDIA Inc.'): nan,\n",
       " ('IBM', 'IBM Corp.'): 3.9144124360393073,\n",
       " ('Google', 'Google Inc.'): 3.9144124360393073,\n",
       " ('FCB', 'Football Club Barcelona'): nan,\n",
       " ('NYC', 'NY City'): 4.532921321014106}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectation_maximization(query_answers, 0.1, tables_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba0c62e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-------------------------------------------------------+---------------------------+---------------------------+---------+---------+\n",
      "|    |   id | pgTitle                                               | sectionTitle              | tableCaption              |   prior | score   |\n",
      "|----+------+-------------------------------------------------------+---------------------------+---------------------------+---------+---------|\n",
      "|  0 |    0 | Mid Antrim (Northern Ireland Parliament constituency) | Members of Parliament     | Members of Parliament     |     0.5 |         |\n",
      "|  1 |    1 | Römer (crater)                                        | Satellite craters         | Satellite craters         |     0.5 |         |\n",
      "|  2 |    2 | Whispermoon                                           |                           | Track listing             |     0.5 |         |\n",
      "|  3 |    3 | Khalsa Diwan Society Vancouver                        | First executive committee | First executive committee |     0.5 |         |\n",
      "|  4 |    4 | Julien Leparoux                                       | Year-end charts           | Year-end charts           |     0.5 |         |\n",
      "|  5 |    5 | Barton Academy (Vermont)                              | Principals                | Principals                |     0.5 |         |\n",
      "|  6 |    6 | Real Voice                                            | Charts                    | Charts                    |     0.5 |         |\n",
      "|  7 |    7 | Acrimony                                              | Albums                    | Albums                    |     0.5 |         |\n",
      "|  8 |    8 | Acrimony                                              | EPs and Singles           | EPs and Singles           |     0.5 |         |\n",
      "|  9 |    9 | James Fiennes, 1st Baron Saye and Sele                | Ancestry                  | Ancestry                  |     0.5 |         |\n",
      "+----+------+-------------------------------------------------------+---------------------------+---------------------------+---------+---------+\n",
      "Time=423[423ms]\n",
      "\n",
      "         121975 function calls (121036 primitive calls) in 0.421 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        5    0.155    0.031    0.155    0.031 {built-in method io.open}\n",
      "        2    0.039    0.019    0.099    0.049 tabdata.py:50(<listcomp>)\n",
      "    20403    0.024    0.000    0.039    0.000 tabdata.py:46(tab2tup)\n",
      "        1    0.021    0.021    0.021    0.021 tabdata.py:108(<dictcomp>)\n",
      "    20598    0.021    0.000    0.021    0.000 tabdata.py:10(rm_nl)\n",
      "    20579    0.016    0.000    0.016    0.000 {method 'split' of 'str' objects}\n",
      "     5284    0.015    0.000    0.022    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "     1313    0.009    0.000    0.013    0.000 porter.py:248(_apply_rule_list)\n",
      "     4464    0.006    0.000    0.007    0.000 __init__.py:315(_subx)\n",
      "      164    0.006    0.000    0.028    0.000 destructive.py:121(tokenize)\n",
      "       31    0.005    0.000    0.005    0.000 {built-in method nt.stat}\n",
      "        1    0.005    0.005    0.334    0.334 3515335508.py:1(create_projections)\n",
      "    13310    0.004    0.000    0.004    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.004    0.004    0.004    0.004 {built-in method _imp.create_dynamic}\n",
      "        1    0.004    0.004    0.004    0.004 {built-in method pandas._libs.json.ujson_loads}\n",
      "        2    0.003    0.001    0.003    0.002 tabdata.py:44(<setcomp>)\n",
      "     1276    0.003    0.000    0.003    0.000 util.py:911(ngrams)\n",
      "      165    0.003    0.000    0.003    0.000 {built-in method maketrans}\n",
      "        1    0.002    0.002    0.122    0.122 tabdata.py:105(tab2intdict)\n",
      "      253    0.002    0.000    0.022    0.000 porter.py:656(stem)\n",
      "      154    0.002    0.000    0.002    0.000 wcwidth.py:160(wcswidth)\n",
      "      218    0.002    0.000    0.007    0.000 porter.py:437(_step2)\n",
      "    48/10    0.002    0.000    0.005    0.000 _parser.py:509(_parse)\n",
      "3427/3370    0.001    0.000    0.004    0.000 {built-in method builtins.isinstance}\n",
      "     60/9    0.001    0.000    0.003    0.000 _compiler.py:37(_compile)\n",
      "        2    0.001    0.001    0.001    0.001 {built-in method io.open_code}\n",
      "   278/18    0.001    0.000    0.002    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "       37    0.001    0.000    0.003    0.000 base.py:510(find)\n",
      "      218    0.001    0.000    0.006    0.000 porter.py:545(_step4)\n",
      "      363    0.001    0.000    0.001    0.000 base.py:236(construct_from_string)\n",
      "      165    0.001    0.000    0.302    0.002 2716206265.py:1(process_words)\n",
      "2841/2644    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      165    0.001    0.000    0.003    0.000 punkt.py:1353(_match_potential_end_contexts)\n",
      "      719    0.001    0.000    0.001    0.000 _parser.py:233(__next)\n",
      "        3    0.001    0.000    0.006    0.002 construction.py:96(arrays_to_mgr)\n",
      "       42    0.001    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:96(_path_join)\n",
      "    69/20    0.001    0.000    0.001    0.000 _parser.py:174(getwidth)\n",
      "        1    0.001    0.001    0.001    0.001 {pandas._libs.lib.fast_unique_multiple_list_gen}\n",
      "        2    0.001    0.000    0.035    0.017 _json.py:1074(__next__)\n",
      "        6    0.001    0.000    0.001    0.000 {method '__exit__' of '_io._IOBase' objects}\n",
      "     1424    0.001    0.000    0.001    0.000 {method 'setdefault' of 'dict' objects}\n",
      "      329    0.001    0.000    0.005    0.000 punkt.py:1441(_realign_boundaries)\n",
      "     2017    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "      329    0.001    0.000    0.005    0.000 punkt.py:1318(span_tokenize)\n",
      "        2    0.001    0.000    0.001    0.000 {method 'read' of '_io.BufferedReader' objects}\n",
      "      403    0.001    0.000    0.001    0.000 _parser.py:164(__getitem__)\n",
      "       35    0.001    0.000    0.001    0.000 {pandas._libs.lib.maybe_convert_objects}\n",
      "        1    0.001    0.001    0.001    0.001 {built-in method _operator.gt}\n",
      "      218    0.001    0.000    0.002    0.000 porter.py:517(_step3)\n",
      "      330    0.001    0.000    0.004    0.000 punkt.py:1427(_slices_from_text)\n",
      "      167    0.001    0.000    0.001    0.000 {method 'translate' of 'str' objects}\n",
      "      218    0.001    0.000    0.001    0.000 porter.py:303(_step1b)\n",
      "       72    0.001    0.000    0.001    0.000 porter.py:147(_measure)\n",
      "        4    0.001    0.000    0.007    0.002 {pandas._libs.tslib.array_with_unit_to_datetime}\n",
      "     1430    0.001    0.000    0.001    0.000 {method 'add' of 'set' objects}\n",
      "      576    0.000    0.000    0.001    0.000 _parser.py:254(get)\n",
      "       44    0.000    0.000    0.001    0.000 __init__.py:958(_padright)\n",
      "       79    0.000    0.000    0.001    0.000 generic.py:6206(__setattr__)\n",
      "       27    0.000    0.000    0.003    0.000 common.py:1587(pandas_dtype)\n",
      "       37    0.000    0.000    0.001    0.000 _parser.py:224(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_all_arraylike}\n",
      "        4    0.000    0.000    0.002    0.001 frame.py:3853(__getitem__)\n",
      "        3    0.000    0.000    0.001    0.000 managers.py:2137(_form_blocks)\n",
      "        3    0.000    0.000    0.006    0.002 <frozen importlib._bootstrap>:1054(_find_spec)\n",
      "      218    0.000    0.000    0.002    0.000 porter.py:276(_step1a)\n",
      "       24    0.000    0.000    0.002    0.000 construction.py:519(sanitize_array)\n",
      "      218    0.000    0.000    0.001    0.000 porter.py:387(_step1c)\n",
      "        3    0.000    0.000    0.000    0.000 {method '_rebuild_blknos_and_blklocs' of 'pandas._libs.internals.BlockManager' objects}\n",
      "      165    0.000    0.000    0.006    0.000 punkt.py:1340(<listcomp>)\n",
      "      165    0.000    0.000    0.000    0.000 {method 'finditer' of 're.Pattern' objects}\n",
      "      165    0.000    0.000    0.297    0.002 __init__.py:127(word_tokenize)\n",
      "       15    0.000    0.000    0.020    0.001 _json.py:1204(_try_convert_data)\n",
      "     22/9    0.000    0.000    0.005    0.001 _parser.py:449(_parse_sub)\n",
      "       51    0.000    0.000    0.000    0.000 {built-in method _codecs.utf_8_decode}\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:991(iget)\n",
      "       28    0.000    0.000    0.001    0.000 _parser.py:999(parse_template)\n",
      "       51    0.000    0.000    0.001    0.000 <frozen codecs>:319(decode)\n",
      "       26    0.000    0.000    0.000    0.000 generic.py:274(__init__)\n",
      "       18    0.000    0.000    0.001    0.000 astype.py:56(_astype_nansafe)\n",
      "      165    0.000    0.000    0.028    0.000 __init__.py:143(<listcomp>)\n",
      "       17    0.000    0.000    0.010    0.001 __init__.py:272(_compile)\n",
      "      165    0.000    0.000    0.006    0.000 punkt.py:1331(sentences_from_text)\n",
      "        9    0.000    0.000    0.004    0.000 <frozen importlib._bootstrap_external>:1604(find_spec)\n",
      "      330    0.000    0.000    0.004    0.000 punkt.py:313(_pair_iter)\n",
      "       27    0.000    0.000    0.000    0.000 _compiler.py:241(_optimize_charset)\n",
      "      165    0.000    0.000    0.006    0.000 punkt.py:1276(tokenize)\n",
      "       35    0.000    0.000    0.000    0.000 numeric.py:274(full)\n",
      "      218    0.000    0.000    0.001    0.000 porter.py:641(_step5b)\n",
      "      165    0.000    0.000    0.269    0.002 __init__.py:109(sent_tokenize)\n",
      "  403/400    0.000    0.000    0.000    0.000 porter.py:126(_is_consonant)\n",
      "      253    0.000    0.000    0.022    0.000 2318274634.py:1(stem_cached)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.listdir}\n",
      "       31    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "       35    0.000    0.000    0.001    0.000 _dtype.py:346(_name_get)\n",
      "      130    0.000    0.000    0.000    0.000 __init__.py:825(_isconvertible)\n",
      "        9    0.000    0.000    0.001    0.000 managers.py:2224(_merge_blocks)\n",
      "        7    0.000    0.000    0.003    0.000 __init__.py:1105(_align_column)\n",
      "        2    0.000    0.000    0.012    0.006 _json.py:1282(_try_convert_to_date)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method marshal.loads}\n",
      "      361    0.000    0.000    0.000    0.000 {method 'update' of 'set' objects}\n",
      "       69    0.000    0.000    0.000    0.000 managers.py:1949(dtype)\n",
      "       19    0.000    0.000    0.000    0.000 generic.py:6147(__finalize__)\n",
      "       90    0.000    0.000    0.000    0.000 numerictypes.py:283(issubclass_)\n",
      "        3    0.000    0.000    0.001    0.000 managers.py:1669(_interleave)\n",
      "      218    0.000    0.000    0.001    0.000 porter.py:605(_step5a)\n",
      "       34    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "      493    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "       65    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        4    0.000    0.000    0.002    0.000 base.py:478(__new__)\n",
      "      167    0.000    0.000    0.000    0.000 generic.py:42(_instancecheck)\n",
      "       18    0.000    0.000    0.000    0.000 managers.py:2194(_stack_arrays)\n",
      "       45    0.000    0.000    0.001    0.000 numerictypes.py:357(issubdtype)\n",
      "       70    0.000    0.000    0.000    0.000 __init__.py:1154(_more_generic)\n",
      "      292    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:638(_extract_index)\n",
      "       30    0.000    0.000    0.003    0.000 frame.py:4402(_get_item_cache)\n",
      "        5    0.000    0.000    0.001    0.000 series.py:371(__init__)\n",
      "       70    0.000    0.000    0.001    0.000 __init__.py:883(_type)\n",
      "      130    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "       27    0.000    0.000    0.000    0.000 warnings.py:487(__exit__)\n",
      "        3    0.000    0.000    0.001    0.000 construction.py:596(_homogenize)\n",
      "       62    0.000    0.000    0.000    0.000 2806311066.py:2(<listcomp>)\n",
      "        1    0.000    0.000    0.258    0.258 punkt.py:1757(load_punkt_params)\n",
      "      186    0.000    0.000    0.000    0.000 _parser.py:172(append)\n",
      "      111    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:778(spec_from_file_location)\n",
      "      167    0.000    0.000    0.000    0.000 generic.py:37(_check)\n",
      "       34    0.000    0.000    0.000    0.000 base.py:5350(__getitem__)\n",
      "      185    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "      214    0.000    0.000    0.000    0.000 util.py:868(pad_sequence)\n",
      "       82    0.000    0.000    0.000    0.000 porter.py:240(_replace_suffix)\n",
      "        9    0.000    0.000    0.009    0.001 _compiler.py:738(compile)\n",
      "       71    0.000    0.000    0.002    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      893    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "       15    0.000    0.000    0.004    0.000 managers.py:308(apply)\n",
      "       17    0.000    0.000    0.000    0.000 frame.py:651(_sliced_from_mgr)\n",
      "        9    0.000    0.000    0.001    0.000 _compiler.py:509(_compile_info)\n",
      "        2    0.000    0.000    0.011    0.006 _json.py:1396(_process_converter)\n",
      "        3    0.000    0.000    0.011    0.004 frame.py:665(__init__)\n",
      "      165    0.000    0.000    0.002    0.000 punkt.py:282(period_context_re)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:437(cache_from_source)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:539(<genexpr>)\n",
      "       18    0.000    0.000    0.000    0.000 _asarray.py:27(require)\n",
      "   278/18    0.000    0.000    0.002    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:1062(<listcomp>)\n",
      "      462    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        1    0.000    0.000    0.008    0.008 __init__.py:1552(tabulate)\n",
      "       33    0.000    0.000    0.000    0.000 dtypes.py:814(construct_from_string)\n",
      "        5    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
      "       33    0.000    0.000    0.000    0.000 dtypes.py:1266(construct_from_string)\n",
      "       70    0.000    0.000    0.000    0.000 __init__.py:833(_isnumber)\n",
      "       17    0.000    0.000    0.002    0.000 frame.py:3776(_ixs)\n",
      "      604    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.004    0.004 data.py:467(find)\n",
      "       17    0.000    0.000    0.000    0.000 series.py:1372(_set_as_cached)\n",
      "       27    0.000    0.000    0.000    0.000 warnings.py:466(__enter__)\n",
      "       33    0.000    0.000    0.000    0.000 dtypes.py:1021(construct_from_string)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'close' of '_io.TextIOWrapper' objects}\n",
      "        4    0.000    0.000    0.000    0.000 base.py:5300(__contains__)\n",
      "       59    0.000    0.000    0.000    0.000 wcwidth.py:115(wcwidth)\n",
      "        3    0.000    0.000    0.001    0.000 <frozen genericpath>:16(exists)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1740(<listcomp>)\n",
      "       17    0.000    0.000    0.001    0.000 cast.py:1147(maybe_infer_to_datetimelike)\n",
      "       27    0.000    0.000    0.000    0.000 warnings.py:181(_add_filter)\n",
      "  184/183    0.000    0.000    0.004    0.000 {built-in method builtins.next}\n",
      "       15    0.000    0.000    0.003    0.000 astype.py:192(astype_array_safe)\n",
      "        9    0.000    0.000    0.006    0.001 _parser.py:972(parse)\n",
      "       17    0.000    0.000    0.001    0.000 frame.py:4384(_box_col_values)\n",
      "        4    0.000    0.000    0.000    0.000 common.py:367(apply_if_callable)\n",
      "       43    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_list_like}\n",
      "      147    0.000    0.000    0.000    0.000 _parser.py:249(match)\n",
      "       18    0.000    0.000    0.000    0.000 blocks.py:198(_consolidate_key)\n",
      "       18    0.000    0.000    0.000    0.000 enum.py:1509(__and__)\n",
      "       33    0.000    0.000    0.000    0.000 dtypes.py:332(construct_from_string)\n",
      "        1    0.000    0.000    0.006    0.006 __init__.py:1(<module>)\n",
      "      309    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
      "      170    0.000    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "       15    0.000    0.000    0.006    0.000 generic.py:6368(astype)\n",
      "        9    0.000    0.000    0.000    0.000 managers.py:225(set_axis)\n",
      "      256    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "       46    0.000    0.000    0.000    0.000 _parser.py:1008(addgroup)\n",
      "       19    0.000    0.000    0.000    0.000 flags.py:89(allows_duplicate_labels)\n",
      "      136    0.000    0.000    0.001    0.000 {built-in method builtins.max}\n",
      "        3    0.000    0.000    0.006    0.002 _strptime.py:309(_strptime)\n",
      "        2    0.000    0.000    0.003    0.002 <frozen importlib._bootstrap_external>:1007(get_code)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:69(shape)\n",
      "        1    0.000    0.000    0.000    0.000 _json.py:960(_combine_lines)\n",
      "        4    0.000    0.000    0.008    0.002 datetimes.py:721(to_datetime)\n",
      "       28    0.000    0.000    0.002    0.000 frame.py:1392(items)\n",
      "       19    0.000    0.000    0.000    0.000 inference.py:273(is_dict_like)\n",
      "       90    0.000    0.000    0.000    0.000 __init__.py:855(_isint)\n",
      "      157    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 missing.py:261(_isna_array)\n",
      "       15    0.000    0.000    0.004    0.000 managers.py:405(astype)\n",
      "       69    0.000    0.000    0.000    0.000 series.py:626(dtype)\n",
      "       33    0.000    0.000    0.000    0.000 string_.py:135(construct_from_string)\n",
      "       33    0.000    0.000    0.000    0.000 dtypes.py:1789(construct_from_string)\n",
      "        3    0.000    0.000    0.003    0.001 managers.py:2068(create_block_manager_from_column_arrays)\n",
      "        3    0.000    0.000    0.001    0.000 managers.py:2207(_consolidate)\n",
      "       42    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:119(<listcomp>)\n",
      "        9    0.000    0.000    0.003    0.000 _compiler.py:571(_code)\n",
      "       39    0.000    0.000    0.000    0.000 {method 'match' of 're.Pattern' objects}\n",
      "       80    0.000    0.000    0.000    0.000 range.py:963(__len__)\n",
      "       17    0.000    0.000    0.001    0.000 frame.py:654(_constructor_sliced_from_mgr)\n",
      "      3/2    0.000    0.000    0.014    0.007 <frozen importlib._bootstrap>:1165(_find_and_load)\n",
      "       27    0.000    0.000    0.000    0.000 _compiler.py:214(_compile_charset)\n",
      "       18    0.000    0.000    0.001    0.000 astype.py:158(astype_array)\n",
      "       33    0.000    0.000    0.000    0.000 dtypes.py:2180(construct_from_string)\n",
      "       78    0.000    0.000    0.000    0.000 __init__.py:33(using_copy_on_write)\n",
      "        5    0.000    0.000    0.000    0.000 shape_base.py:219(vstack)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:649(_simple_new)\n",
      "        1    0.000    0.000    0.038    0.038 common.py:652(get_handle)\n",
      "        1    0.000    0.000    0.001    0.001 base.py:7092(_cmp_method)\n",
      "       35    0.000    0.000    0.000    0.000 _dtype.py:330(_name_includes_bit_suffix)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:340(__init__)\n",
      "       29    0.000    0.000    0.000    0.000 blocks.py:2346(get_block_type)\n",
      "     12/8    0.000    0.000    0.000    0.000 _compiler.py:434(_get_literal_prefix)\n",
      "       18    0.000    0.000    0.001    0.000 base.py:7521(ensure_index)\n",
      "        1    0.000    0.000    0.006    0.006 3558573592.py:1(create_tables_df)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:43(using_pyarrow_string_dtype)\n",
      "       27    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "        5    0.000    0.000    0.000    0.000 common.py:103(_maybe_match_name)\n",
      "        4    0.000    0.000    0.001    0.000 datetimes.py:216(_maybe_cache)\n",
      "       20    0.000    0.000    0.000    0.000 construction.py:695(_sanitize_ndim)\n",
      "       18    0.000    0.000    0.000    0.000 construction.py:485(ensure_wrapped_if_datetimelike)\n",
      "       19    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "       19    0.000    0.000    0.000    0.000 enum.py:686(__call__)\n",
      "       13    0.000    0.000    0.001    0.000 construction.py:1028(convert)\n",
      "        1    0.000    0.000    0.262    0.262 punkt.py:1746(load_lang)\n",
      "       13    0.000    0.000    0.000    0.000 _json.py:1442(is_ok)\n",
      "        3    0.000    0.000    0.005    0.002 <frozen importlib._bootstrap_external>:1464(_get_spec)\n",
      "      3/2    0.000    0.000    0.014    0.007 <frozen importlib._bootstrap>:1120(_find_and_load_unlocked)\n",
      "       19    0.000    0.000    0.000    0.000 enum.py:1091(__new__)\n",
      "       23    0.000    0.000    0.000    0.000 common.py:296(maybe_iterable_to_list)\n",
      "        1    0.000    0.000    0.009    0.009 _json.py:1360(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1655(_fill_cache)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen codecs>:309(__init__)\n",
      "       22    0.000    0.000    0.000    0.000 warnings.py:165(simplefilter)\n",
      "        7    0.000    0.000    0.001    0.000 __init__.py:1150(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:2293(is_unique)\n",
      "       18    0.000    0.000    0.000    0.000 porter.py:219(_ends_cvc)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "       15    0.000    0.000    0.000    0.000 _parser.py:309(_class_escape)\n",
      "       27    0.000    0.000    0.000    0.000 warnings.py:440(__init__)\n",
      "       15    0.000    0.000    0.002    0.000 common.py:1268(is_extension_array_dtype)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:1349(_iter_member_by_value_)\n",
      "       77    0.000    0.000    0.000    0.000 __init__.py:1527(_to_str)\n",
      "        8    0.000    0.000    0.000    0.000 config.py:127(_get_single_key)\n",
      "       71    0.000    0.000    0.002    0.000 <frozen abc>:117(__instancecheck__)\n",
      "        7    0.000    0.000    0.000    0.000 __init__.py:1094(_flat_list)\n",
      "       28    0.000    0.000    0.001    0.000 __init__.py:305(_compile_repl)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:487(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:1825(from_array)\n",
      "        1    0.000    0.000    0.000    0.000 socket.py:545(send)\n",
      "      237    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "        2    0.000    0.000    0.001    0.000 array_ops.py:191(_na_arithmetic_op)\n",
      "        7    0.000    0.000    0.001    0.000 __init__.py:1049(_align_column_choose_padfn)\n",
      "       17    0.000    0.000    0.000    0.000 blocks.py:1007(iget)\n",
      "       40    0.000    0.000    0.000    0.000 __init__.py:104(_is_separating_line)\n",
      "       91    0.000    0.000    0.000    0.000 _parser.py:160(__len__)\n",
      "       11    0.000    0.000    0.000    0.000 construction.py:915(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 cast.py:1400(find_common_type)\n",
      "        1    0.000    0.000    0.002    0.002 construction.py:891(_list_of_dict_to_arrays)\n",
      "        5    0.000    0.000    0.000    0.000 cast.py:1544(construct_1d_object_array_from_listlike)\n",
      "       15    0.000    0.000    0.004    0.000 blocks.py:588(astype)\n",
      "       39    0.000    0.000    0.000    0.000 {built-in method numpy.asarray}\n",
      "        5    0.000    0.000    0.000    0.000 cast.py:119(maybe_convert_platform)\n",
      "        5    0.000    0.000    0.000    0.000 base.py:836(__iter__)\n",
      "       26    0.000    0.000    0.000    0.000 flags.py:53(__init__)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'get_loc' of 'pandas._libs.index.IndexEngine' objects}\n",
      "       73    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_np_dtype}\n",
      "        3    0.000    0.000    0.001    0.000 _strptime.py:238(pattern)\n",
      "       61    0.000    0.000    0.000    0.000 _parser.py:109(__init__)\n",
      "       30    0.000    0.000    0.000    0.000 __init__.py:918(_afterpoint)\n",
      "       26    0.000    0.000    0.000    0.000 managers.py:1960(internal_values)\n",
      "        1    0.000    0.000    0.001    0.001 arraylike.py:54(__gt__)\n",
      "       38    0.000    0.000    0.000    0.000 {method 'search' of 're.Pattern' objects}\n",
      "        3    0.000    0.000    0.006    0.002 _strptime.py:565(_strptime_datetime)\n",
      "       17    0.000    0.000    0.000    0.000 base.py:3763(get_loc)\n",
      "       18    0.000    0.000    0.000    0.000 generic.py:335(_from_mgr)\n",
      "       60    0.000    0.000    0.000    0.000 __init__.py:869(_isbool)\n",
      "       50    0.000    0.000    0.000    0.000 _parser.py:286(tell)\n",
      "       30    0.000    0.000    0.000    0.000 construction.py:420(extract_array)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:1308(_normalize_tabular_data)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:179(_get_module_lock)\n",
      "       61    0.000    0.000    0.000    0.000 {method 'find' of 'bytearray' objects}\n",
      "       32    0.000    0.000    0.000    0.000 managers.py:2124(_grouping_func)\n",
      "       11    0.000    0.000    0.000    0.000 _parser.py:82(opengroup)\n",
      "       42    0.000    0.000    0.000    0.000 inference.py:334(is_hashable)\n",
      "        2    0.000    0.000    0.006    0.003 construction.py:423(dict_to_mgr)\n",
      "        2    0.000    0.000    0.002    0.001 <frozen importlib._bootstrap_external>:1127(get_data)\n",
      "        9    0.000    0.000    0.000    0.000 generic.py:760(_set_axis)\n",
      "        1    0.000    0.000    0.011    0.011 common.py:1176(_get_binary_io_classes)\n",
      "        7    0.000    0.000    0.001    0.000 __init__.py:1197(<listcomp>)\n",
      "      3/2    0.000    0.000    0.010    0.005 <frozen importlib._bootstrap>:666(_load_unlocked)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:842(_engine)\n",
      "        5    0.000    0.000    0.001    0.000 warnings.py:130(filterwarnings)\n",
      "        2    0.000    0.000    0.001    0.000 array_ops.py:290(comparison_op)\n",
      "        5    0.000    0.000    0.001    0.000 <frozen genericpath>:27(isfile)\n",
      "       43    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:244(_verbose_message)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'add_index_reference' of 'pandas._libs.internals.BlockValuesRefs' objects}\n",
      "        3    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap>:493(_init_module_attrs)\n",
      "       11    0.000    0.000    0.000    0.000 blocks.py:2317(maybe_coerce_values)\n",
      "        1    0.000    0.000    0.011    0.011 _json.py:1422(_try_convert_types)\n",
      "        1    0.000    0.000    0.039    0.039 _json.py:912(_get_data_from_filepath)\n",
      "        7    0.000    0.000    0.000    0.000 __init__.py:2154(<listcomp>)\n",
      "       72    0.000    0.000    0.000    0.000 {method 'count' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 blocks.py:2375(new_block_2d)\n",
      "        4    0.000    0.000    0.007    0.002 datetimes.py:369(_convert_listlike_datetimes)\n",
      "       81    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "        8    0.000    0.000    0.000    0.000 config.py:145(_get_option)\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _functools.reduce}\n",
      "        2    0.000    0.000    0.073    0.037 1953859970.py:1(iter_json)\n",
      "       13    0.000    0.000    0.000    0.000 _parser.py:267(getuntil)\n",
      "       18    0.000    0.000    0.000    0.000 _asarray.py:108(<setcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen ntpath>:570(abspath)\n",
      "        5    0.000    0.000    0.000    0.000 _compiler.py:386(<listcomp>)\n",
      "        1    0.000    0.000    0.011    0.011 _optional.py:81(import_optional_dependency)\n",
      "       53    0.000    0.000    0.000    0.000 inference.py:300(<genexpr>)\n",
      "       16    0.000    0.000    0.000    0.000 config.py:647(_get_deprecated_option)\n",
      "       36    0.000    0.000    0.000    0.000 managers.py:2212(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:666(_parse)\n",
      "        1    0.000    0.000    0.000    0.000 astype.py:139(_astype_float_to_int_nansafe)\n",
      "        1    0.000    0.000    0.039    0.039 _json.py:816(__init__)\n",
      "        6    0.000    0.000    0.000    0.000 blocks.py:2388(new_block)\n",
      "       16    0.000    0.000    0.000    0.000 <frozen _collections_abc>:78(_check_methods)\n",
      "        4    0.000    0.000    0.001    0.000 {built-in method builtins.sorted}\n",
      "        7    0.000    0.000    0.000    0.000 iostream.py:624(write)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.003    0.003 __init__.py:2169(<listcomp>)\n",
      "       70    0.000    0.000    0.000    0.000 __init__.py:1201(_format)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:202(union_indexes)\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.dicts_to_array}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _locale.setlocale}\n",
      "       16    0.000    0.000    0.000    0.000 series.py:784(_references)\n",
      "        3    0.000    0.000    0.000    0.000 cast.py:1359(np_find_common_type)\n",
      "        8    0.000    0.000    0.000    0.000 config.py:633(_get_root)\n",
      "       34    0.000    0.000    0.000    0.000 common.py:149(cast_scalar_indexer)\n",
      "       77    0.000    0.000    0.001    0.000 __init__.py:2179(<genexpr>)\n",
      "      137    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_iscased}\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1599(_get_spec)\n",
      "        1    0.000    0.000    0.039    0.039 _json.py:500(read_json)\n",
      "       33    0.000    0.000    0.000    0.000 __init__.py:947(_padleft)\n",
      "        8    0.000    0.000    0.000    0.000 _compiler.py:465(_get_charset_prefix)\n",
      "        2    0.000    0.000    0.009    0.005 <frozen importlib._bootstrap_external>:934(exec_module)\n",
      "        2    0.000    0.000    0.000    0.000 parse.py:374(urlparse)\n",
      "        1    0.000    0.000    0.013    0.013 _json.py:1185(_convert_axes)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:928(_finalize_columns_and_data)\n",
      "        3    0.000    0.000    0.001    0.000 base.py:1038(astype)\n",
      "       33    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x00007FFAA0FFA4B0}\n",
      "        6    0.000    0.000    0.000    0.000 range.py:198(_simple_new)\n",
      "        8    0.000    0.000    0.000    0.000 config.py:271(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2330(_format_table)\n",
      "      104    0.000    0.000    0.000    0.000 <frozen _collections_abc>:409(__subclasshook__)\n",
      "        2    0.000    0.000    0.001    0.000 expressions.py:95(_evaluate_numexpr)\n",
      "        3    0.000    0.000    0.001    0.000 managers.py:1596(as_array)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:73(_validate_set_axis)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen ntpath>:107(join)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "        9    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
      "       10    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:1421(_path_importer_cache)\n",
      "        4    0.000    0.000    0.007    0.002 datetimes.py:526(_to_datetime_with_unit)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:71(__init__)\n",
      "       26    0.000    0.000    0.000    0.000 series.py:750(_values)\n",
      "       13    0.000    0.000    0.007    0.001 _json.py:1429(<lambda>)\n",
      "        1    0.000    0.000    0.001    0.001 data.py:202(normalize_resource_name)\n",
      "        1    0.000    0.000    0.033    0.033 _json.py:1022(_get_object_parser)\n",
      "        5    0.000    0.000    0.000    0.000 shape_base.py:81(atleast_2d)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:172(_path_isabs)\n",
      "        2    0.000    0.000    0.011    0.006 common.py:1155(_is_binary_mode)\n",
      "       48    0.000    0.000    0.000    0.000 common.py:1255(is_1d_only_ea_dtype)\n",
      "       10    0.000    0.000    0.000    0.000 base.py:7616(maybe_extract_name)\n",
      "       23    0.000    0.000    0.000    0.000 managers.py:1799(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 construction.py:734(_sanitize_str_dtypes)\n",
      "        6    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:150(_path_is_mode_type)\n",
      "       11    0.000    0.000    0.000    0.000 series.py:653(name)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:100(acquire)\n",
      "       18    0.000    0.000    0.003    0.000 <frozen importlib._bootstrap_external>:140(_path_stat)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:452(urlsplit)\n",
      "        3    0.000    0.000    0.002    0.001 managers.py:1744(_consolidate_inplace)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:3218(union)\n",
      "       18    0.000    0.000    0.000    0.000 blocks.py:192(_can_consolidate)\n",
      "       30    0.000    0.000    0.000    0.000 __init__.py:984(_strip_ansi)\n",
      "       51    0.000    0.000    0.000    0.000 {method 'strip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:1369(_missing_)\n",
      "       26    0.000    0.000    0.000    0.000 base.py:909(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:481(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1734(_consolidate_check)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen genericpath>:39(isdir)\n",
      "        9    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:67(_relax_case)\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method _sre.compile}\n",
      "        3    0.000    0.000    0.005    0.002 <frozen importlib._bootstrap>:566(module_from_spec)\n",
      "       78    0.000    0.000    0.000    0.000 <frozen _collections_abc>:262(__subclasshook__)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.setattr}\n",
      "       35    0.000    0.000    0.000    0.000 _dtype.py:24(_kind_name)\n",
      "        5    0.000    0.000    0.000    0.000 _compiler.py:384(_mk_bitmap)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1371(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 data.py:302(__init__)\n",
      "       40    0.000    0.000    0.000    0.000 _parser.py:79(groups)\n",
      "        1    0.000    0.000    0.000    0.000 nturl2path.py:8(url2pathname)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:289(_get_filepath_or_buffer)\n",
      "      7/4    0.000    0.000    0.006    0.002 <frozen importlib._bootstrap>:233(_call_with_frames_removed)\n",
      "        1    0.000    0.000    0.003    0.003 construction.py:793(to_arrays)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _operator.eq}\n",
      "        7    0.000    0.000    0.000    0.000 _parser.py:446(_uniq)\n",
      "       46    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
      "       14    0.000    0.000    0.008    0.001 __init__.py:225(compile)\n",
      "        6    0.000    0.000    0.000    0.000 series.py:703(name)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:567(_get_cached)\n",
      "       19    0.000    0.000    0.000    0.000 blocks.py:187(is_extension)\n",
      "        7    0.000    0.000    0.000    0.000 __init__.py:1147(<listcomp>)\n",
      "       13    0.000    0.000    0.000    0.000 base.py:61(__len__)\n",
      "        5    0.000    0.000    0.000    0.000 generic.py:562(_get_axis)\n",
      "       10    0.000    0.000    0.000    0.000 blocks.py:2467(extend_blocks)\n",
      "        3    0.000    0.000    0.000    0.000 _parser.py:77(get_token)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:538(infer_compression)\n",
      "       35    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_integer}\n",
      "       17    0.000    0.000    0.000    0.000 _parser.py:369(_escape)\n",
      "       13    0.000    0.000    0.000    0.000 _json.py:1462(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'all' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.001    0.001 series.py:5794(_cmp_method)\n",
      "       35    0.000    0.000    0.000    0.000 blocks.py:583(dtype)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:125(release)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method fromkeys}\n",
      "        5    0.000    0.000    0.000    0.000 api.py:379(default_index)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:3191(_validate_sort_keyword)\n",
      "       11    0.000    0.000    0.000    0.000 __init__.py:2237(<listcomp>)\n",
      "      122    0.000    0.000    0.000    0.000 {built-in method _sre.unicode_tolower}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:132(_path_split)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1408(_path_hooks)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:642(_classify_pyc)\n",
      "        1    0.000    0.000    0.000    0.000 punkt.py:224(_re_non_word_chars)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:1260(_remove_separating_lines)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:727(_compile_bytecode)\n",
      "        3    0.000    0.000    0.000    0.000 locale.py:479(_parse_localename)\n",
      "       18    0.000    0.000    0.000    0.000 porter.py:573(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1559(__init__)\n",
      "       14    0.000    0.000    0.000    0.000 __init__.py:2243(_build_simple_row)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1683(<listcomp>)\n",
      "       23    0.000    0.000    0.000    0.000 managers.py:1902(_block)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:2233(<listcomp>)\n",
      "        1    0.000    0.000    0.033    0.033 _json.py:1172(parse)\n",
      "        1    0.000    0.000    0.004    0.004 <frozen importlib._bootstrap_external>:1231(create_module)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:173(_expand_user)\n",
      "        1    0.000    0.000    0.003    0.003 construction.py:506(nested_data_to_arrays)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen ntpath>:154(splitdrive)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:253(escape)\n",
      "       11    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:521(_cmpkey)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen os>:674(__getitem__)\n",
      "        4    0.000    0.000    0.000    0.000 __init__.py:1070(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1280(_prepend_row_index)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:169(__enter__)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method math.isinf}\n",
      "        2    0.000    0.000    0.006    0.003 {built-in method builtins.exec}\n",
      "       18    0.000    0.000    0.000    0.000 _compiler.py:568(isstring)\n",
      "        9    0.000    0.000    0.000    0.000 _parser.py:73(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:6156(all)\n",
      "        3    0.000    0.000    0.000    0.000 _parser.py:189(__next__)\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:1068(<listcomp>)\n",
      "       12    0.000    0.000    0.000    0.000 porter.py:398(nltk_condition)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen ntpath>:319(expanduser)\n",
      "        2    0.000    0.000    0.001    0.000 expressions.py:226(evaluate)\n",
      "        6    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:84(_unpack_uint32)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:184(_isna)\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:1025(argsort)\n",
      "       27    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 common.py:233(stringify_path)\n",
      "       23    0.000    0.000    0.000    0.000 base.py:5127(_values)\n",
      "        8    0.000    0.000    0.000    0.000 _compiler.py:396(_simple)\n",
      "       20    0.000    0.000    0.000    0.000 construction.py:754(_maybe_repeat)\n",
      "        1    0.000    0.000    0.001    0.001 2806311066.py:1(create_table_list)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:1726(is_consolidated)\n",
      "        8    0.000    0.000    0.000    0.000 enum.py:193(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:258(schedule)\n",
      "        1    0.000    0.000    0.000    0.000 punkt.py:209(_re_sent_end_chars)\n",
      "       11    0.000    0.000    0.001    0.000 _parser.py:94(closegroup)\n",
      "        5    0.000    0.000    0.000    0.000 generic.py:6189(__getattr__)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method builtins.format}\n",
      "        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "        9    0.000    0.000    0.000    0.000 _parser.py:956(fix_flags)\n",
      "       17    0.000    0.000    0.000    0.000 common.py:556(require_length_match)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:1064(<listcomp>)\n",
      "        8    0.000    0.000    0.000    0.000 _parser.py:297(checkgroupname)\n",
      "        3    0.000    0.000    0.000    0.000 locale.py:593(getlocale)\n",
      "        3    0.000    0.000    0.006    0.002 _strptime.py:261(compile)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.print}\n",
      "       38    0.000    0.000    0.000    0.000 generic.py:393(flags)\n",
      "       13    0.000    0.000    0.000    0.000 series.py:821(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _imp.is_builtin}\n",
      "        1    0.000    0.000    0.000    0.000 platform.py:1111(python_implementation)\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method nt._path_splitroot}\n",
      "        4    0.000    0.000    0.000    0.000 indexing.py:2678(check_dict_or_set_indexers)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "        6    0.000    0.000    0.000    0.000 frame.py:1539(__len__)\n",
      "       27    0.000    0.000    0.000    0.000 base.py:71(<genexpr>)\n",
      "        7    0.000    0.000    0.001    0.000 __init__.py:1175(_column_type)\n",
      "       15    0.000    0.000    0.000    0.000 inspect.py:292(isclass)\n",
      "        2    0.000    0.000    0.000    0.000 punkt.py:338(__init__)\n",
      "       38    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_float}\n",
      "       20    0.000    0.000    0.000    0.000 _compiler.py:426(_get_iscased)\n",
      "        8    0.000    0.000    0.000    0.000 config.py:686(_warn_if_deprecated)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:347(interleaved_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2167(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 locale.py:396(normalize)\n",
      "        1    0.000    0.000    0.002    0.002 _json.py:1432(_try_convert_dates)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:134(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:581(_constructor_from_mgr)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:89(find_spec)\n",
      "        5    0.000    0.000    0.000    0.000 common.py:81(get_op_result_name)\n",
      "        4    0.000    0.000    0.000    0.000 cast.py:1483(construct_1d_arraylike_from_scalar)\n",
      "        8    0.000    0.000    0.000    0.000 config.py:615(_select_options)\n",
      "        6    0.000    0.000    0.000    0.000 porter.py:198(_has_positive_measure)\n",
      "        1    0.000    0.000    0.000    0.000 tabdata.py:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:199(split)\n",
      "        1    0.000    0.000    0.001    0.001 range.py:1030(_cmp_method)\n",
      "        5    0.000    0.000    0.000    0.000 porter.py:201(_contains_vowel)\n",
      "        1    0.000    0.000    0.000    0.000 readers.py:518(validate_integer)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1562(validate_all_hashable)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1122(get_filename)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen codecs>:260(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1030(__exit__)\n",
      "       52    0.000    0.000    0.000    0.000 typing.py:2256(cast)\n",
      "        3    0.000    0.000    0.001    0.000 frame.py:12207(values)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:137(is_object_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2182(<listcomp>)\n",
      "        2    0.000    0.000    0.002    0.001 common.py:62(new_method)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen zipimport>:64(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:208(isnum)\n",
      "        5    0.000    0.000    0.000    0.000 generic.py:487(_validate_dtype)\n",
      "        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:392(cached)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:131(dispatch_fill_zeros)\n",
      "       17    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
      "       15    0.000    0.000    0.000    0.000 managers.py:235(items)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1696(path_hook_for_FileFinder)\n",
      "        4    0.000    0.000    0.000    0.000 base.py:448(size)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:574(_ensure_array)\n",
      "        4    0.000    0.000    0.000    0.000 frame.py:4399(_clear_item_cache)\n",
      "        3    0.000    0.000    0.005    0.002 <frozen importlib._bootstrap_external>:1496(find_spec)\n",
      "       29    0.000    0.000    0.000    0.000 <frozen _collections_abc>:315(__subclasshook__)\n",
      "        6    0.000    0.000    0.000    0.000 common.py:1322(is_ea_or_datetimelike_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:62(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen ntpath>:538(normpath)\n",
      "       19    0.000    0.000    0.000    0.000 _compiler.py:31(_combine_flags)\n",
      "       10    0.000    0.000    0.000    0.000 __init__.py:1471(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 wcwidth.py:228(_wcmatch_version)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:366(ensure_np_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:121(close)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:234(_data)\n",
      "        9    0.000    0.000    0.000    0.000 blocks.py:2245(get_values)\n",
      "       18    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen _collections_abc>:771(get)\n",
      "        5    0.000    0.000    0.001    0.000 <frozen importlib._bootstrap_external>:159(_path_isfile)\n",
      "       35    0.000    0.000    0.000    0.000 multiarray.py:1080(copyto)\n",
      "        2    0.000    0.000    0.001    0.000 expressions.py:67(_evaluate_standard)\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:169(blknos)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:2130(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:357(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:5885(_construct_result)\n",
      "        9    0.000    0.000    0.000    0.000 base.py:831(_reset_identity)\n",
      "        3    0.000    0.000    0.000    0.000 parse.py:119(_coerce_args)\n",
      "       14    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "        1    0.000    0.000    0.001    0.001 construction.py:1006(convert_object_array)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2153(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:173(__exit__)\n",
      "        5    0.000    0.000    0.000    0.000 shape_base.py:207(_arrays_for_stack_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:145(is_url)\n",
      "        3    0.000    0.000    0.000    0.000 base.py:592(_dtype_to_subclass)\n",
      "        8    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_iterator}\n",
      "        2    0.000    0.000    0.099    0.050 tabdata.py:49(tab2tups)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 _strptime.py:26(_getlang)\n",
      "        1    0.000    0.000    0.000    0.000 punkt.py:539(__init__)\n",
      "       11    0.000    0.000    0.000    0.000 __init__.py:2234(_pad_row)\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method _imp.release_lock}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1146(path_stats)\n",
      "        5    0.000    0.000    0.000    0.000 shape_base.py:215(_vhstack_dispatcher)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:977(is_numeric_v_string_like)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:395(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 wcwidth.py:88(_bisearch)\n",
      "        2    0.000    0.000    0.000    0.000 missing.py:101(isna)\n",
      "       23    0.000    0.000    0.000    0.000 blocks.py:239(mgr_locs)\n",
      "       11    0.000    0.000    0.000    0.000 _json.py:965(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:198(cb)\n",
      "       17    0.000    0.000    0.000    0.000 managers.py:185(blklocs)\n",
      "       11    0.000    0.000    0.000    0.000 __init__.py:2259(_append_basic_row)\n",
      "        9    0.000    0.000    0.000    0.000 _parser.py:168(__setitem__)\n",
      "       12    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1026(__enter__)\n",
      "        2    0.000    0.000    0.003    0.002 tabdata.py:43(txt2set)\n",
      "        1    0.000    0.000    0.011    0.011 <frozen importlib._bootstrap>:1192(_gcd_import)\n",
      "        4    0.000    0.000    0.000    0.000 missing.py:642(na_value_for_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:3746(_assert_can_do_setop)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen os>:748(encodekey)\n",
      "       20    0.000    0.000    0.000    0.000 {method 'group' of 're.Match' objects}\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:349(<genexpr>)\n",
      "       11    0.000    0.000    0.000    0.000 __init__.py:2249(_build_row)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:221(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 {pandas._libs.lib.dtypes_all_equal}\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1185(is_alive)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:323(_sanitize_and_check)\n",
      "        1    0.000    0.000    0.262    0.262 punkt.py:1742(__init__)\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method _imp.acquire_lock}\n",
      "       12    0.000    0.000    0.000    0.000 common.py:1581(<genexpr>)\n",
      "       18    0.000    0.000    0.000    0.000 {built-in method nt.fspath}\n",
      "       19    0.000    0.000    0.000    0.000 generic.py:358(attrs)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt._getfullpathname}\n",
      "        1    0.000    0.000    0.000    0.000 range.py:134(__new__)\n",
      "        8    0.000    0.000    0.000    0.000 config.py:674(_translate_key)\n",
      "        1    0.000    0.000    0.000    0.000 _json.py:965(<listcomp>)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:2178(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _json.py:1126(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:404(is_dataclass)\n",
      "        7    0.000    0.000    0.000    0.000 iostream.py:519(_is_master_process)\n",
      "        8    0.000    0.000    0.000    0.000 {pandas._libs.lib.item_from_zerodim}\n",
      "       27    0.000    0.000    0.000    0.000 base.py:1657(name)\n",
      "        1    0.000    0.000    0.000    0.000 series.py:6094(_reduce)\n",
      "        7    0.000    0.000    0.000    0.000 __init__.py:1075(_align_column_choose_width_fn)\n",
      "        3    0.000    0.000    0.000    0.000 _methods.py:61(_all)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:1383(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:922(<listcomp>)\n",
      "        5    0.000    0.000    0.000    0.000 porter.py:382(<lambda>)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:920(find_spec)\n",
      "        6    0.000    0.000    0.000    0.000 generic.py:548(_get_axis_number)\n",
      "        1    0.000    0.000    0.000    0.000 _json.py:1049(close)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:2300(_build_line)\n",
      "       13    0.000    0.000    0.000    0.000 {method 'isidentifier' of 'str' objects}\n",
      "       19    0.000    0.000    0.000    0.000 flags.py:57(allows_duplicate_labels)\n",
      "        3    0.000    0.000    0.002    0.001 generic.py:4461(get)\n",
      "        7    0.000    0.000    0.000    0.000 __init__.py:1237(_align_header)\n",
      "        9    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       15    0.000    0.000    0.000    0.000 managers.py:335(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:5153(_get_engine_target)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:675(_validate_timestamp_pyc)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:599(_check_name_wrapper)\n",
      "        5    0.000    0.000    0.000    0.000 construction.py:687(_sanitize_non_ordered)\n",
      "        3    0.000    0.000    0.000    0.000 common.py:1425(_is_dtype_type)\n",
      "       12    0.000    0.000    0.000    0.000 cast.py:1430(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 inference.py:105(is_file_like)\n",
      "        1    0.000    0.000    0.262    0.262 __init__.py:96(_get_punkt_tokenizer)\n",
      "        3    0.000    0.000    0.000    0.000 construction.py:196(mgr_to_mgr)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:277(is_fsspec_url)\n",
      "       15    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       19    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:48(_new_module)\n",
      "        1    0.000    0.000    0.000    0.000 blocks.py:247(make_block)\n",
      "        1    0.000    0.000    0.000    0.000 1428111118.py:5(print_time)\n",
      "        5    0.000    0.000    0.000    0.000 porter.py:208(_ends_double_consonant)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:748(find_spec)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:1499(__or__)\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:1359(_iter_member_by_def_)\n",
      "       10    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        2    0.000    0.000    0.001    0.000 __init__.py:173(search)\n",
      "        1    0.000    0.000    0.001    0.001 arraylike.py:38(__eq__)\n",
      "        4    0.000    0.000    0.000    0.000 data.py:338(__str__)\n",
      "        4    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:405(parent)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'stream_reader' of 'zstd.ZstdDecompressor' objects}\n",
      "        4    0.000    0.000    0.000    0.000 base.py:675(empty)\n",
      "       12    0.000    0.000    0.000    0.000 range.py:377(dtype)\n",
      "       12    0.000    0.000    0.000    0.000 cast.py:1446(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 managers.py:1812(from_blocks)\n",
      "        1    0.000    0.000    0.011    0.011 __init__.py:108(import_module)\n",
      "       13    0.000    0.000    0.000    0.000 _json.py:1401(<lambda>)\n",
      "        7    0.000    0.000    0.000    0.000 iostream.py:546(_schedule_flush)\n",
      "        3    0.000    0.000    0.000    0.000 range.py:554(equals)\n",
      "        1    0.000    0.000    0.000    0.000 1428111118.py:2(get_clock_time_in_milli_sec)\n",
      "        6    0.000    0.000    0.000    0.000 {method 'index' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:2312(_append_line)\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method math.isnan}\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:668(range_to_ndarray)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:765(_try_cast)\n",
      "       10    0.000    0.000    0.000    0.000 <frozen _collections_abc>:283(__subclasshook__)\n",
      "        3    0.000    0.000    0.000    0.000 _parser.py:203(isword)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:3752(_convert_can_do_setop)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:2015(empty)\n",
      "        5    0.000    0.000    0.000    0.000 managers.py:2242(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "       11    0.000    0.000    0.000    0.000 __init__.py:2109(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2346(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen ntpath>:87(isabs)\n",
      "        8    0.000    0.000    0.000    0.000 enum.py:1249(value)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1141(file_exists)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'translate' of 'bytearray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1066(is_numeric_dtype)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _imp._fix_co_filename}\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:322(weekday)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1239(exec_module)\n",
      "       14    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "        4    0.000    0.000    0.000    0.000 datetimes.py:156(should_cache)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1022(_is_multiline)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen _collections_abc>:381(__subclasshook__)\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of 'zstd.ZstdDecompressionReader' objects}\n",
      "        6    0.000    0.000    0.000    0.000 cast.py:1439(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:532(treat_as_nested)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen os>:1081(__subclasshook__)\n",
      "       17    0.000    0.000    0.000    0.000 base.py:6612(_maybe_cast_indexer)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1097(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 expressions.py:76(_can_use_numexpr)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1684(<setcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 base.py:3180(_get_reconciled_name_object)\n",
      "        1    0.000    0.000    0.000    0.000 punkt.py:1248(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:165(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:163(match)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1948(__iter__)\n",
      "        3    0.000    0.000    0.000    0.000 __init__.py:2308(<listcomp>)\n",
      "        8    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1565(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:1381(_indexed_same)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method nt._path_normpath}\n",
      "        1    0.000    0.000    0.000    0.000 common.py:514(is_string_or_object_np_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2161(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen _collections_abc>:362(__subclasshook__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:459(_engine_type)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "        7    0.000    0.000    0.000    0.000 {method 'partition' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method _imp.find_frozen}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.checknull}\n",
      "        3    0.000    0.000    0.000    0.000 enum.py:117(_iter_bits_lsb)\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "        1    0.000    0.000    0.000    0.000 api.py:344(<setcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 multiarray.py:153(concatenate)\n",
      "        2    0.000    0.000    0.000    0.000 <frozen os>:742(check_str)\n",
      "        1    0.000    0.000    0.000    0.000 platform.py:1007(_sys_version)\n",
      "        1    0.000    0.000    0.000    0.000 _validators.py:226(validate_bool_kwarg)\n",
      "        1    0.000    0.000    0.000    0.000 construction.py:950(_validate_or_indexify_columns)\n",
      "        2    0.000    0.000    0.000    0.000 dispatch.py:17(should_extension_dispatch)\n",
      "        2    0.000    0.000    0.000    0.000 generic.py:2073(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 tabdata.py:16(TabEncoder)\n",
      "        6    0.000    0.000    0.000    0.000 __init__.py:471(_parse_letter_version)\n",
      "       11    0.000    0.000    0.000    0.000 range.py:464(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 dataclasses.py:1256(is_dataclass)\n",
      "        2    0.000    0.000    0.000    0.000 <string>:1(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:164(_path_isdir)\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:659(unquote)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:2(__init__)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:1118(_wait_for_tstate_lock)\n",
      "        6    0.000    0.000    0.000    0.000 cast.py:1441(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:230(is_single_block)\n",
      "        1    0.000    0.000    0.000    0.000 _json.py:896(_preprocess_data)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'clear' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 nanops.py:543(nanall)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:150(__lt__)\n",
      "        7    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.locals}\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:137(_event_pipe)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:281(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:329(month)\n",
      "        4    0.000    0.000    0.000    0.000 {method 'read' of '_io.StringIO' objects}\n",
      "        3    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:342(ampm)\n",
      "        1    0.000    0.000    0.000    0.000 tabdata.py:38(TabDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:213(isspace)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1220(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 enum.py:1445(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:131(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:121(classes)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2337(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method nt.getcwd}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method nt.getpid}\n",
      "        2    0.000    0.000    0.000    0.000 enum.py:1366(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 _optional.py:70(get_version)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1025(needs_i8_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:791(is_)\n",
      "        2    0.000    0.000    0.000    0.000 construction.py:916(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:1034(_choose_width_fn)\n",
      "        3    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:413(has_location)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:1107(_maybe_memory_map)\n",
      "        4    0.000    0.000    0.000    0.000 __init__.py:535(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 _validators.py:450(check_dtype_backend)\n",
      "        5    0.000    0.000    0.000    0.000 series.py:1381(_clear_item_cache)\n",
      "        1    0.000    0.000    0.001    0.001 __init__.py:2203(_expand_numparse)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1101(_sanity_check)\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:1021(_argsort_dispatcher)\n",
      "        7    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:319(jump)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:2220(_expand_iterable)\n",
      "        2    0.000    0.000    0.000    0.000 common.py:123(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
      "        5    0.000    0.000    0.000    0.000 shape_base.py:77(_atleast_2d_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 inference.py:306(is_named_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 generic.py:638(_info_axis)\n",
      "        2    0.000    0.000    0.000    0.000 blocks.py:1003(shape)\n",
      "        1    0.000    0.000    0.000    0.000 common.py:503(get_compression_method)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:281(start)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'isalpha' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 managers.py:896(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 {method 'isdecimal' of 'str' objects}\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:509(_parse_local_version)\n",
      "        2    0.000    0.000    0.000    0.000 series.py:577(_constructor)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'find' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 common.py:126(_classes_and_not_datetimelike)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _codecs.lookup_error}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'isascii' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _imp.exec_dynamic}\n",
      "        4    0.000    0.000    0.000    0.000 base.py:363(ndim)\n",
      "        1    0.000    0.000    0.000    0.000 porter.py:653(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "        2    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:931(create_module)\n",
      "        1    0.000    0.000    0.000    0.000 function.py:64(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:974(dtype)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:299(stop)\n",
      "        1    0.000    0.000    0.000    0.000 tabdata.py:65(MaxentEncoder)\n",
      "        1    0.000    0.000    0.000    0.000 tabdata.py:103(PunktDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_bool}\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:568(is_set)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:316(step)\n",
      "        1    0.000    0.000    0.000    0.000 porter.py:593(<lambda>)\n",
      "        2    0.000    0.000    0.000    0.000 __init__.py:1274(_reinsert_separating_lines)\n",
      "        1    0.000    0.000    0.000    0.000 tabdata.py:80(MaxentDecoder)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdigit' of 'str' objects}\n",
      "        3    0.000    0.000    0.000    0.000 parse.py:108(_noop)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'groups' of 're.Match' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isspace' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 unicode_versions.py:8(list_versions)\n",
      "        3    0.000    0.000    0.000    0.000 multiarray.py:669(result_type)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method from_iterable}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 parse.py:421(_checknetloc)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:1056(_could_be_tzname)\n",
      "        1    0.000    0.000    0.000    0.000 range.py:213(_validate_dtype)\n",
      "        1    0.000    0.000    0.000    0.000 _json.py:1059(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 _parser.py:186(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 api.py:282(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:96(<lambda>)\n",
      "\n",
      "\n",
      "defaultdict(<class 'dict'>, {('1929', 'Robert Crawford'): {0: {(0, (1, 2))}}, ('1933', 'Robert Crawford'): {0: {(1, (1, 2))}}})\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    csize = 10\n",
    "    path = \"../data/tables_10.json\"\n",
    "\n",
    "    start_table_index = 0\n",
    "\n",
    "    projections = dict()\n",
    "    tables_df = pd.DataFrame()\n",
    "\n",
    "    c = get_clock_time_in_milli_sec()\n",
    "\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "\n",
    "    for table_chunk in iter_json(path, csize):\n",
    "        \n",
    "        table_list = create_table_list(table_chunk)\n",
    "\n",
    "        projections = create_projections(table_list, start_table_index, projections, ps, create_ngrams=True, min_word_len=3)\n",
    "\n",
    "        tables_df = create_tables_df(table_chunk, start_table_index, tables_df)\n",
    "\n",
    "        start_table_index += csize\n",
    "\n",
    "    print(tabulate(tables_df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "    c = get_clock_time_in_milli_sec() - c\n",
    "\n",
    "    print(\"Time=\", end=\"\")\n",
    "    print_time(c)\n",
    "    print()\n",
    "\n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler)\n",
    "    stats.strip_dirs()\n",
    "    stats.sort_stats(\"time\")\n",
    "    stats.print_stats()\n",
    "\n",
    "    indexing_examples = [('1929', 'Robert Crawford'), ('1933', 'Robert Crawford')]\n",
    "    # multikey_indexing_example = [(('1929', 'Robert Crawford'), 'Ulster Unionist')]\n",
    "    tau = 1\n",
    "    final_list_single_key_dict = defaultdict(dict)\n",
    "\n",
    "    for indexing_example in indexing_examples:\n",
    "\n",
    "        dict_test = querry_thunel([indexing_example], projections, tau)\n",
    "        final_list_single_key_dict[indexing_example].update(dict_test)\n",
    "    \n",
    "    # final_list_muli_key = querry_thunel(multikey_indexing_example, projections, tau)\n",
    "\n",
    "    # expectation_maximization(final_list_single_key_dict, projections)\n",
    "\n",
    "    print(final_list_single_key_dict)\n",
    "    # print(final_list_muli_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ebd1475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- III-C (1/4): purge index entries that point outside current table_list ---\n",
    "\n",
    "def purge_bad_postings(projections, table_list):\n",
    "    \"\"\"\n",
    "    Remove any (tid, rid, cid) that point outside table_list bounds.\n",
    "    Returns number of removed postings.\n",
    "    \"\"\"\n",
    "    removed = 0\n",
    "    max_tid = len(table_list) - 1\n",
    "    for token in list(projections.keys()):\n",
    "        postings = projections[token]\n",
    "        good = set()\n",
    "        for (tid, rid, cid) in postings:\n",
    "            if not (0 <= tid <= max_tid):\n",
    "                continue\n",
    "            tbl = table_list[tid]\n",
    "            if not (0 <= rid < len(tbl)):\n",
    "                continue\n",
    "            row = tbl[rid]\n",
    "            if not (0 <= cid < len(row)):\n",
    "                continue\n",
    "            good.add((tid, rid, cid))\n",
    "        if good:\n",
    "            removed += (len(postings) - len(good))\n",
    "            projections[token] = good\n",
    "        else:\n",
    "            removed += len(postings)\n",
    "            del projections[token]\n",
    "    return removed\n",
    "\n",
    "# Run once to sanitize the current projections\n",
    "_ = purge_bad_postings(projections, table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec32c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- III-C (2/4): guarded lookups used only by part C ---\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def _value_hits(projections, value, create_ngrams=False, ngram_size=2):\n",
    "    toks = cleaner(value, create_ngrams, ngram_size)\n",
    "    postings = set()\n",
    "    for t in toks:\n",
    "        postings |= projections.get(t, set())\n",
    "    return postings\n",
    "\n",
    "def rows_containing_value_in_col(table_list, table_id, col_id, value, create_ngrams=False, ngram_size=2):\n",
    "    if not (0 <= table_id < len(table_list)):\n",
    "        return set()\n",
    "    toks = set(cleaner(value, create_ngrams, ngram_size))\n",
    "    if not toks:\n",
    "        return set()\n",
    "    rows = set()\n",
    "    tbl = table_list[table_id]\n",
    "    for r, row in enumerate(tbl):\n",
    "        if 0 <= col_id < len(row):\n",
    "            cell = \"\" if row[col_id] is None else str(row[col_id])\n",
    "            cell_toks = set(cleaner(cell, create_ngrams, ngram_size))\n",
    "            if toks.issubset(cell_toks):\n",
    "                rows.add(r)\n",
    "    return rows\n",
    "\n",
    "def candidate_cols_for_values(table_list, projections, values, tau, create_ngrams=False, ngram_size=2):\n",
    "    hits_by_table_col = defaultdict(set)  # (tid, cid) -> set(values_matched)\n",
    "    max_tid = len(table_list) - 1\n",
    "    for v in values:\n",
    "        for (tid, rid, cid) in _value_hits(projections, v, create_ngrams, ngram_size):\n",
    "            if not (0 <= tid <= max_tid):\n",
    "                continue\n",
    "            tbl = table_list[tid]\n",
    "            if not (0 <= rid < len(tbl)):\n",
    "                continue\n",
    "            row = tbl[rid]\n",
    "            if not (0 <= cid < len(row)):\n",
    "                continue\n",
    "            hits_by_table_col[(tid, cid)].add(v)\n",
    "    out = defaultdict(set)  # tid -> {cid,...}\n",
    "    for (tid, cid), matched in hits_by_table_col.items():\n",
    "        if len(matched) >= tau:\n",
    "            out[tid].add(cid)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff33038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Patch: stronger value lookup for III-C when numbers weren't indexed ---\n",
    "\n",
    "def _value_hits(projections, value, create_ngrams=False, ngram_size=2):\n",
    "    toks = cleaner(value, create_ngrams, ngram_size)\n",
    "    postings = set()\n",
    "    for t in toks:\n",
    "        postings |= projections.get(t, set())\n",
    "\n",
    "    if postings:\n",
    "        return postings\n",
    "\n",
    "    # Fallback: numeric (or mixed) values often weren't token-indexed by A/B.\n",
    "    needle = str(value).strip()\n",
    "    if needle and any(ch.isdigit() for ch in needle):\n",
    "        for tid, tbl in enumerate(table_list):\n",
    "            for rid, row in enumerate(tbl):\n",
    "                for cid, cell in enumerate(row):\n",
    "                    if cell is None:\n",
    "                        continue\n",
    "                    if needle in str(cell):\n",
    "                        postings.add((tid, rid, cid))\n",
    "    return postings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52e9a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- III-C (3/4): Section III-C core (indirect transformations via joins) ---\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "def fd_holds_X_to_Z_on_examples(table_list, table_id, x_col, z_col, E_x_to_y, tau, create_ngrams=False, ngram_size=2):\n",
    "    ok = 0\n",
    "    seen_contradiction = False\n",
    "    for x_val, _ in E_x_to_y:\n",
    "        x_rows = rows_containing_value_in_col(table_list, table_id, x_col, x_val, create_ngrams, ngram_size)\n",
    "        if not x_rows:\n",
    "            continue\n",
    "        z_vals = set()\n",
    "        for r in x_rows:\n",
    "            row = table_list[table_id][r]\n",
    "            if 0 <= z_col < len(row):\n",
    "                z_vals.add(str(row[z_col]))\n",
    "        if len(z_vals) == 1:\n",
    "            ok += 1\n",
    "        elif len(z_vals) > 1:\n",
    "            seen_contradiction = True\n",
    "    return (ok >= tau) and (not seen_contradiction)\n",
    "\n",
    "def fd_holds_Z_to_Y_on_examples(table_list, table_id, z_col, y_col, E_x_to_y, tau, create_ngrams=False, ngram_size=2):\n",
    "    ok = 0\n",
    "    seen_contradiction = False\n",
    "    # We verify that, for at least tau examples, all matching rows agree on Y (unique Y per Z).\n",
    "    for _, y_val in E_x_to_y:\n",
    "        # here we don't have the exact Z per example; we conservatively check consistency where y tokens match\n",
    "        y_tokens = set(cleaner(str(y_val), create_ngrams, ngram_size))\n",
    "        if not y_tokens:\n",
    "            continue\n",
    "        y_vals_found = set()\n",
    "        tbl = table_list[table_id]\n",
    "        for r, row in enumerate(tbl):\n",
    "            if 0 <= z_col < len(row) and 0 <= y_col < len(row):\n",
    "                y_cell = \"\" if row[y_col] is None else str(row[y_col])\n",
    "                if y_tokens.issubset(set(cleaner(y_cell, create_ngrams, ngram_size))):\n",
    "                    y_vals_found.add(y_cell)\n",
    "        if len(y_vals_found) == 1:\n",
    "            ok += 1\n",
    "        elif len(y_vals_found) > 1:\n",
    "            seen_contradiction = True\n",
    "    return (ok >= tau) and (not seen_contradiction)\n",
    "\n",
    "def extract_Z_set(table_list, table_id, x_col, z_col, X_values, create_ngrams=False, ngram_size=2):\n",
    "    Z = set()\n",
    "    lineage = defaultdict(set)  # x -> {z,...}\n",
    "    for x_val in X_values:\n",
    "        x_rows = rows_containing_value_in_col(table_list, table_id, x_col, x_val, create_ngrams, ngram_size)\n",
    "        for r in x_rows:\n",
    "            row = table_list[table_id][r]\n",
    "            if 0 <= z_col < len(row):\n",
    "                z = str(row[z_col])\n",
    "                Z.add(z)\n",
    "                lineage[str(x_val)].add(z)\n",
    "    return Z, dict(lineage)\n",
    "\n",
    "def find_join_columns(table_list, projections, E, tau=2, create_ngrams=False, ngram_size=2):\n",
    "    \"\"\"\n",
    "    Find, per table, columns (x_col, z_col) where X -> Z holds on >= tau examples.\n",
    "    Returns: {table_id: [ {x_col, z_col, Z, x_to_z_lineage}, ... ]}\n",
    "    \"\"\"\n",
    "    E_x_to_y = [(str(x), str(y)) for (x, y) in E]\n",
    "    X_values = {x for x, _ in E_x_to_y}\n",
    "\n",
    "    x_cols_by_table = candidate_cols_for_values(table_list, projections, X_values, tau, create_ngrams, ngram_size)\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    for tid, x_cols in x_cols_by_table.items():\n",
    "        if not (0 <= tid < len(table_list)):\n",
    "            continue\n",
    "        tbl = table_list[tid]\n",
    "        num_cols = max((len(r) for r in tbl), default=0)\n",
    "        for x_col in x_cols:\n",
    "            for z_col in range(num_cols):\n",
    "                if z_col == x_col:\n",
    "                    continue\n",
    "                if fd_holds_X_to_Z_on_examples(table_list, tid, x_col, z_col, E_x_to_y, tau, create_ngrams, ngram_size):\n",
    "                    Z, x2z = extract_Z_set(table_list, tid, x_col, z_col, X_values, create_ngrams, ngram_size)\n",
    "                    # cardinality sanity check: Z should be large enough to be useful\n",
    "                    if len(Z) >= len({y for _, y in E_x_to_y}):\n",
    "                        results[tid].append({\n",
    "                            \"x_col\": x_col,\n",
    "                            \"z_col\": z_col,\n",
    "                            \"Z\": Z,\n",
    "                            \"x_to_z_lineage\": x2z,\n",
    "                        })\n",
    "    return results\n",
    "\n",
    "def find_joinable_tables(table_list, projections, Z_set, Y_values, tau=2, create_ngrams=False, ngram_size=2):\n",
    "    \"\"\"\n",
    "    Given candidate Z values, find tables having a Z column (>= tau matches) and a Y column with Z -> Y (>= tau).\n",
    "    \"\"\"\n",
    "    z_cols_by_table = candidate_cols_for_values(table_list, projections, Z_set, tau, create_ngrams, ngram_size)\n",
    "    joined = []\n",
    "    E_dummy = [(None, str(y)) for y in Y_values]  # only Y is used in the Z->Y check\n",
    "\n",
    "    for tid, z_cols in z_cols_by_table.items():\n",
    "        if not (0 <= tid < len(table_list)):\n",
    "            continue\n",
    "        tbl = table_list[tid]\n",
    "        num_cols = max((len(r) for r in tbl), default=0)\n",
    "        for z_col in z_cols:\n",
    "            # support: how many Z from Z_set actually appear in this column\n",
    "            matched_Z = set()\n",
    "            for z in Z_set:\n",
    "                if rows_containing_value_in_col(table_list, tid, z_col, z, create_ngrams, ngram_size):\n",
    "                    matched_Z.add(z)\n",
    "            for y_col in range(num_cols):\n",
    "                if y_col == z_col:\n",
    "                    continue\n",
    "                if fd_holds_Z_to_Y_on_examples(table_list, tid, z_col, y_col, E_dummy, tau, create_ngrams, ngram_size):\n",
    "                    joined.append({\n",
    "                        \"table_id\": tid,\n",
    "                        \"z_col\": z_col,\n",
    "                        \"y_col\": y_col,\n",
    "                        \"support\": len(matched_Z),\n",
    "                        \"Z_in_col\": matched_Z,\n",
    "                    })\n",
    "    return joined\n",
    "\n",
    "def table_joiner_bfs(table_list, projections, E, Q, tau=2, max_path_len=1, create_ngrams=False, ngram_size=2):\n",
    "    \"\"\"\n",
    "    Discover indirect X -> Z -> Y transformations satisfying FD constraints on >= tau examples.\n",
    "    \"\"\"\n",
    "    E_x_to_y = [(str(x), str(y)) for (x, y) in E]\n",
    "    X_values = {x for x, _ in E_x_to_y}\n",
    "    Y_values = {y for _, y in E_x_to_y}\n",
    "\n",
    "    # Step 1: discover (T, x_col, z_col) with X -> Z\n",
    "    x_to_z_candidates = find_join_columns(table_list, projections, E_x_to_y, tau, create_ngrams, ngram_size)\n",
    "\n",
    "    results = {\"paths\": [], \"joined_tables\": []}\n",
    "\n",
    "    frontier = deque()\n",
    "    for tid, cand_list in x_to_z_candidates.items():\n",
    "        for c in cand_list:\n",
    "            frontier.append({\n",
    "                \"path\": [{\"table_id\": tid, \"x_col\": c[\"x_col\"], \"z_col\": c[\"z_col\"], \"Z\": c[\"Z\"]}],\n",
    "                \"Z\": c[\"Z\"],\n",
    "                \"depth\": 1\n",
    "            })\n",
    "\n",
    "    visited_Z_snapshots = set()\n",
    "    def z_sig(Z):\n",
    "        # short signature to avoid cycles\n",
    "        return tuple(sorted(list(Z))[:64])\n",
    "\n",
    "    while frontier:\n",
    "        node = frontier.popleft()\n",
    "        Zcur = node[\"Z\"]\n",
    "        sig = z_sig(Zcur)\n",
    "        if sig in visited_Z_snapshots:\n",
    "            continue\n",
    "        visited_Z_snapshots.add(sig)\n",
    "\n",
    "        # Step 2: find tables with Z -> Y\n",
    "        joined = find_joinable_tables(table_list, projections, Zcur, Y_values, tau, create_ngrams, ngram_size)\n",
    "        results[\"joined_tables\"].extend(joined)\n",
    "\n",
    "        # Project Y candidates for query Xs through any matched Z rows (liberal projection)\n",
    "        produced = defaultdict(set)\n",
    "        for j in joined:\n",
    "            tid = j[\"table_id\"]; zc = j[\"z_col\"]; yc = j[\"y_col\"]\n",
    "            tbl = table_list[tid]\n",
    "            for r, row in enumerate(tbl):\n",
    "                if 0 <= zc < len(row) and 0 <= yc < len(row):\n",
    "                    z_val = str(row[zc]); y_val = str(row[yc])\n",
    "                    z_toks = set(cleaner(z_val, create_ngrams, ngram_size))\n",
    "                    for xq in Q:\n",
    "                        if set(cleaner(str(xq), create_ngrams, ngram_size)).issubset(z_toks):\n",
    "                            produced[str(xq)].add(y_val)\n",
    "\n",
    "        results[\"paths\"].append({\n",
    "            \"path_len\": 1,\n",
    "            \"via\": node[\"path\"],\n",
    "            \"covers_tau_examples\": True,   # ensured by FD checks\n",
    "            \"produced_y_for_q\": {k: sorted(list(v)) for k, v in produced.items()}\n",
    "        })\n",
    "\n",
    "        # Step 3: optionally expand to longer chains (X -> Z1 -> Z2 -> ... -> Y)\n",
    "        if node[\"depth\"] < max_path_len:\n",
    "            # Treat current Z as the new X to find Z' with Z -> Z'\n",
    "            E_proxy = [(z, z) for z in Zcur]\n",
    "            z_to_zprime = find_join_columns(table_list, projections, E_proxy, tau, create_ngrams, ngram_size)\n",
    "            for tid2, cand_list2 in z_to_zprime.items():\n",
    "                for c2 in cand_list2:\n",
    "                    frontier.append({\n",
    "                        \"path\": node[\"path\"] + [{\"table_id\": tid2, \"x_col\": c2[\"x_col\"], \"z_col\": c2[\"z_col\"], \"Z\": c2[\"Z\"]}],\n",
    "                        \"Z\": c2[\"Z\"],\n",
    "                        \"depth\": node[\"depth\"] + 1\n",
    "                    })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "080ced7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths': [], 'joined_tables': []}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- III-C (4/4): example call (adjust E/Q and tau to your data) ---\n",
    "\n",
    "E = [('1929', 'Robert Crawford')]  # your example pairs\n",
    "Q = ['1929']                       # Xs to transform\n",
    "\n",
    "out = table_joiner_bfs(\n",
    "    table_list, projections, E, Q,\n",
    "    tau=1,            # use 2+ if you have multiple pairs\n",
    "    max_path_len=1,   # set >1 to allow longer X->Z1->Z2->Y chains\n",
    "    create_ngrams=False,\n",
    "    ngram_size=2\n",
    ")\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add12143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X appears in the following (table_id, col_id) with counts:\n",
      "  T5 C0: matched 1 of 1 X values\n",
      "\n",
      "Samples (first few rows) from those columns:\n",
      "\n",
      "=== T5 C0 (matches 1 Xs) ===\n",
      "r=11: ['1929–30', 'Hancock Hockey Club']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(set, {(5, 0): {'1929'}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- III-C DEBUG (A): where do X-values appear? ---\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "def inspect_x_columns(table_list, projections, X_values, max_samples=5):\n",
    "    by_table_col = defaultdict(set)  # (tid, cid) -> set(X matched)\n",
    "\n",
    "    for x in X_values:\n",
    "        for (tid, rid, cid) in _value_hits(projections, x):\n",
    "            # guards already inside _value_hits/purge, but we keep it safe\n",
    "            if not (0 <= tid < len(table_list)): \n",
    "                continue\n",
    "            row = table_list[tid][rid]\n",
    "            if not (0 <= cid < len(row)):\n",
    "                continue\n",
    "            by_table_col[(tid, cid)].add(x)\n",
    "\n",
    "    # Print summary\n",
    "    if not by_table_col:\n",
    "        print(\"No X hits found in any table/column.\")\n",
    "        return {}\n",
    "\n",
    "    print(\"X appears in the following (table_id, col_id) with counts:\")\n",
    "    for (tid, cid), xs in sorted(by_table_col.items(), key=lambda kv: (-len(kv[1]), kv[0][0], kv[0][1]))[:20]:\n",
    "        print(f\"  T{tid} C{cid}: matched {len(xs)} of {len(X_values)} X values\")\n",
    "\n",
    "    # Sample a few rows from each interesting column\n",
    "    print(\"\\nSamples (first few rows) from those columns:\")\n",
    "    for (tid, cid), xs in itertools.islice(sorted(by_table_col.items(), key=lambda kv: (-len(kv[1]), kv[0][0], kv[0][1])), 5):\n",
    "        print(f\"\\n=== T{tid} C{cid} (matches {len(xs)} Xs) ===\")\n",
    "        tbl = table_list[tid]\n",
    "        shown = 0\n",
    "        for r, row in enumerate(tbl):\n",
    "            if cid < len(row):\n",
    "                val = row[cid]\n",
    "                if val is None:\n",
    "                    continue\n",
    "                text = str(val)\n",
    "                # show rows that contain any X substring\n",
    "                if any(str(x) in text for x in X_values):\n",
    "                    # print the whole row to understand context\n",
    "                    print(f\"r={r}: {row}\")\n",
    "                    shown += 1\n",
    "                    if shown >= max_samples:\n",
    "                        break\n",
    "    return by_table_col\n",
    "\n",
    "inspect_x_columns(table_list, projections, X_values=['1929'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c97f9dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paths': [], 'joined_tables': []}\n"
     ]
    }
   ],
   "source": [
    "# --- III-C DEBUG (B): relaxed FD options ---\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def fd_X_to_Z(table_list, tid, x_col, z_col, E_x_to_y, tau, mode='strict', tol=0, create_ngrams=False, ngram_size=2):\n",
    "    ok = 0\n",
    "    for x_val, _ in E_x_to_y:\n",
    "        rows = rows_containing_value_in_col(table_list, tid, x_col, x_val, create_ngrams, ngram_size)\n",
    "        if not rows:\n",
    "            continue\n",
    "        z_vals = [str(table_list[tid][r][z_col]) for r in rows if 0 <= z_col < len(table_list[tid][r])]\n",
    "        z_vals = [z for z in z_vals if z is not None]\n",
    "        if not z_vals:\n",
    "            continue\n",
    "\n",
    "        if mode == 'strict':\n",
    "            if len(set(z_vals)) == 1:\n",
    "                ok += 1\n",
    "            else:\n",
    "                return False  # any contradiction kills strict\n",
    "        elif mode == 'majority':\n",
    "            c = Counter(z_vals)\n",
    "            maj = c.most_common(1)[0][1]\n",
    "            # tolerate up to 'tol' off-majority appearances\n",
    "            if maj >= len(z_vals) - tol:\n",
    "                ok += 1\n",
    "        elif mode == 'exists':\n",
    "            ok += 1\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'strict', 'majority', or 'exists'\")\n",
    "    return ok >= tau\n",
    "\n",
    "def fd_Z_to_Y(table_list, tid, z_col, y_col, E_x_to_y, tau, mode='strict', tol=0, create_ngrams=False, ngram_size=2):\n",
    "    ok = 0\n",
    "    # We only have Y side in examples; we check that rows agreeing on Y are not contradictory for ≥ tau examples.\n",
    "    for _, y_val in E_x_to_y:\n",
    "        y_toks = set(cleaner(str(y_val), create_ngrams, ngram_size))\n",
    "        if not y_toks:\n",
    "            continue\n",
    "        y_vals_found = []\n",
    "        tbl = table_list[tid]\n",
    "        for r, row in enumerate(tbl):\n",
    "            if 0 <= z_col < len(row) and 0 <= y_col < len(row):\n",
    "                y_cell = \"\" if row[y_col] is None else str(row[y_col])\n",
    "                if y_toks.issubset(set(cleaner(y_cell, create_ngrams, ngram_size))):\n",
    "                    y_vals_found.append(y_cell)\n",
    "        if not y_vals_found:\n",
    "            continue\n",
    "        if mode == 'strict':\n",
    "            if len(set(y_vals_found)) == 1:\n",
    "                ok += 1\n",
    "            else:\n",
    "                return False\n",
    "        elif mode == 'majority':\n",
    "            c = Counter(y_vals_found)\n",
    "            maj = c.most_common(1)[0][1]\n",
    "            if maj >= len(y_vals_found) - tol:\n",
    "                ok += 1\n",
    "        elif mode == 'exists':\n",
    "            ok += 1\n",
    "    return ok >= tau\n",
    "\n",
    "# Wrappers that use relaxed FDs\n",
    "def find_join_columns_relaxed(table_list, projections, E, tau=2, mode='strict', tol=0, create_ngrams=False, ngram_size=2):\n",
    "    E_x_to_y = [(str(x), str(y)) for (x, y) in E]\n",
    "    X_values = {x for x, _ in E_x_to_y}\n",
    "    x_cols_by_table = candidate_cols_for_values(table_list, projections, X_values, tau, create_ngrams, ngram_size)\n",
    "    results = defaultdict(list)\n",
    "    for tid, x_cols in x_cols_by_table.items():\n",
    "        if not (0 <= tid < len(table_list)): \n",
    "            continue\n",
    "        tbl = table_list[tid]\n",
    "        num_cols = max((len(r) for r in tbl), default=0)\n",
    "        for x_col in x_cols:\n",
    "            for z_col in range(num_cols):\n",
    "                if z_col == x_col:\n",
    "                    continue\n",
    "                if fd_X_to_Z(table_list, tid, x_col, z_col, E_x_to_y, tau, mode, tol, create_ngrams, ngram_size):\n",
    "                    # collect Z set (same as before)\n",
    "                    Z = set()\n",
    "                    for x_val, _ in E_x_to_y:\n",
    "                        rows = rows_containing_value_in_col(table_list, tid, x_col, x_val, create_ngrams, ngram_size)\n",
    "                        for r in rows:\n",
    "                            row = table_list[tid][r]\n",
    "                            if 0 <= z_col < len(row):\n",
    "                                Z.add(str(row[z_col]))\n",
    "                    if Z:\n",
    "                        results[tid].append({\"x_col\": x_col, \"z_col\": z_col, \"Z\": Z})\n",
    "    return results\n",
    "\n",
    "def find_joinable_tables_relaxed(table_list, projections, Z_set, Y_values, tau=2, mode='strict', tol=0, create_ngrams=False, ngram_size=2):\n",
    "    z_cols_by_table = candidate_cols_for_values(table_list, projections, Z_set, tau, create_ngrams, ngram_size)\n",
    "    joined = []\n",
    "    E_dummy = [(None, str(y)) for y in Y_values]\n",
    "    for tid, z_cols in z_cols_by_table.items():\n",
    "        if not (0 <= tid < len(table_list)):\n",
    "            continue\n",
    "        tbl = table_list[tid]\n",
    "        num_cols = max((len(r) for r in tbl), default=0)\n",
    "        for z_col in z_cols:\n",
    "            for y_col in range(num_cols):\n",
    "                if y_col == z_col:\n",
    "                    continue\n",
    "                if fd_Z_to_Y(table_list, tid, z_col, y_col, E_dummy, tau, mode, tol, create_ngrams, ngram_size):\n",
    "                    joined.append({\"table_id\": tid, \"z_col\": z_col, \"y_col\": y_col})\n",
    "    return joined\n",
    "\n",
    "def table_joiner_bfs_relaxed(table_list, projections, E, Q, tau=1, mode='majority', tol=1, create_ngrams=False, ngram_size=2):\n",
    "    E_x_to_y = [(str(x), str(y)) for (x, y) in E]\n",
    "    X_values = {x for x, _ in E_x_to_y}\n",
    "    Y_values = {y for _, y in E_x_to_y}\n",
    "    x2z = find_join_columns_relaxed(table_list, projections, E_x_to_y, tau, mode, tol, create_ngrams, ngram_size)\n",
    "    results = {\"paths\": [], \"joined_tables\": []}\n",
    "    for tid, lst in x2z.items():\n",
    "        for c in lst:\n",
    "            joined = find_joinable_tables_relaxed(table_list, projections, c[\"Z\"], Y_values, tau, mode, tol, create_ngrams, ngram_size)\n",
    "            results[\"joined_tables\"].extend(joined)\n",
    "            # simple projection like before\n",
    "            produced = defaultdict(set)\n",
    "            for j in joined:\n",
    "                t2 = j[\"table_id\"]; zc = j[\"z_col\"]; yc = j[\"y_col\"]\n",
    "                for r, row in enumerate(table_list[t2]):\n",
    "                    if 0 <= zc < len(row) and 0 <= yc < len(row):\n",
    "                        z_val = str(row[zc]); y_val = str(row[yc])\n",
    "                        z_toks = set(cleaner(z_val, create_ngrams, ngram_size))\n",
    "                        for xq in Q:\n",
    "                            if set(cleaner(str(xq), create_ngrams, ngram_size)).issubset(z_toks):\n",
    "                                produced[str(xq)].add(y_val)\n",
    "            results[\"paths\"].append({\n",
    "                \"path_len\": 1,\n",
    "                \"via\": [{\"table_id\": tid, \"x_col\": c[\"x_col\"], \"z_col\": c[\"z_col\"]}],\n",
    "                \"produced_y_for_q\": {k: sorted(list(v)) for k, v in produced.items()}\n",
    "            })\n",
    "    return results\n",
    "\n",
    "# Try relaxed:\n",
    "E = [('1929', 'Robert Crawford')]\n",
    "Q = ['1929']\n",
    "rel = table_joiner_bfs_relaxed(table_list, projections, E, Q, tau=1, mode='exists')\n",
    "print(rel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
